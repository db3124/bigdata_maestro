{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "637/637 [==============================] - 0s 210us/step - loss: 1.2571 - MAE: 131.0152\n",
      "Epoch 2/250\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.5862 - MAE: 111.3854\n",
      "Epoch 3/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.5429 - MAE: 107.6592\n",
      "Epoch 4/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.5361 - MAE: 106.9140\n",
      "Epoch 5/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.5299 - MAE: 106.6950\n",
      "Epoch 6/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.5243 - MAE: 106.4131\n",
      "Epoch 7/250\n",
      "637/637 [==============================] - 0s 92us/step - loss: 0.5167 - MAE: 105.54800s - loss: 0.5312 - MAE: 109.794\n",
      "Epoch 8/250\n",
      "637/637 [==============================] - 0s 52us/step - loss: 0.5082 - MAE: 105.5532\n",
      "Epoch 9/250\n",
      "637/637 [==============================] - 0s 88us/step - loss: 0.4988 - MAE: 104.7143\n",
      "Epoch 10/250\n",
      "637/637 [==============================] - 0s 52us/step - loss: 0.4898 - MAE: 104.0825\n",
      "Epoch 11/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.4792 - MAE: 103.9822\n",
      "Epoch 12/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.4756 - MAE: 103.1261\n",
      "Epoch 13/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.4682 - MAE: 101.8391\n",
      "Epoch 14/250\n",
      "637/637 [==============================] - 0s 87us/step - loss: 0.4533 - MAE: 101.5056\n",
      "Epoch 15/250\n",
      "637/637 [==============================] - 0s 55us/step - loss: 0.4464 - MAE: 100.9142\n",
      "Epoch 16/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.4414 - MAE: 100.6366\n",
      "Epoch 17/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.4258 - MAE: 99.4260\n",
      "Epoch 18/250\n",
      "637/637 [==============================] - 0s 77us/step - loss: 0.4198 - MAE: 99.0130\n",
      "Epoch 19/250\n",
      "637/637 [==============================] - 0s 67us/step - loss: 0.4114 - MAE: 97.8845\n",
      "Epoch 20/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.4066 - MAE: 97.7956\n",
      "Epoch 21/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.4013 - MAE: 97.3008\n",
      "Epoch 22/250\n",
      "637/637 [==============================] - 0s 79us/step - loss: 0.3957 - MAE: 96.4953\n",
      "Epoch 23/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.3868 - MAE: 95.9760\n",
      "Epoch 24/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.3899 - MAE: 95.3540\n",
      "Epoch 25/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.3765 - MAE: 95.0460\n",
      "Epoch 26/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.3763 - MAE: 93.9263\n",
      "Epoch 27/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.3672 - MAE: 94.2784\n",
      "Epoch 28/250\n",
      "637/637 [==============================] - 0s 93us/step - loss: 0.3669 - MAE: 93.9565\n",
      "Epoch 29/250\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.3606 - MAE: 93.6246\n",
      "Epoch 30/250\n",
      "637/637 [==============================] - 0s 54us/step - loss: 0.3572 - MAE: 92.5735\n",
      "Epoch 31/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.3552 - MAE: 91.9896\n",
      "Epoch 32/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.3516 - MAE: 92.3570\n",
      "Epoch 33/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.3474 - MAE: 91.4154\n",
      "Epoch 34/250\n",
      "637/637 [==============================] - 0s 79us/step - loss: 0.3425 - MAE: 90.7429\n",
      "Epoch 35/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.3363 - MAE: 89.6906\n",
      "Epoch 36/250\n",
      "637/637 [==============================] - 0s 87us/step - loss: 0.3385 - MAE: 90.6818\n",
      "Epoch 37/250\n",
      "637/637 [==============================] - 0s 52us/step - loss: 0.3370 - MAE: 89.6984\n",
      "Epoch 38/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.3319 - MAE: 89.3482\n",
      "Epoch 39/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.3302 - MAE: 88.5404\n",
      "Epoch 40/250\n",
      "637/637 [==============================] - 0s 92us/step - loss: 0.3260 - MAE: 88.9204\n",
      "Epoch 41/250\n",
      "637/637 [==============================] - 0s 51us/step - loss: 0.3305 - MAE: 89.0189\n",
      "Epoch 42/250\n",
      "637/637 [==============================] - 0s 95us/step - loss: 0.3242 - MAE: 87.5774\n",
      "Epoch 43/250\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3209 - MAE: 88.1839\n",
      "Epoch 44/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.3198 - MAE: 87.2014\n",
      "Epoch 45/250\n",
      "637/637 [==============================] - 0s 87us/step - loss: 0.3209 - MAE: 87.7898\n",
      "Epoch 46/250\n",
      "637/637 [==============================] - 0s 52us/step - loss: 0.3141 - MAE: 85.7875\n",
      "Epoch 47/250\n",
      "637/637 [==============================] - 0s 93us/step - loss: 0.3210 - MAE: 87.9130\n",
      "Epoch 48/250\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.3169 - MAE: 85.5876\n",
      "Epoch 49/250\n",
      "637/637 [==============================] - 0s 95us/step - loss: 0.3154 - MAE: 86.8297\n",
      "Epoch 50/250\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3127 - MAE: 86.0688\n",
      "Epoch 51/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.3162 - MAE: 86.7452\n",
      "Epoch 52/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.3112 - MAE: 86.1659\n",
      "Epoch 53/250\n",
      "637/637 [==============================] - 0s 54us/step - loss: 0.3104 - MAE: 85.1038\n",
      "Epoch 54/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.3089 - MAE: 85.2309\n",
      "Epoch 55/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.3091 - MAE: 86.0230\n",
      "Epoch 56/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.3088 - MAE: 85.3283\n",
      "Epoch 57/250\n",
      "637/637 [==============================] - 0s 80us/step - loss: 0.3078 - MAE: 85.5807\n",
      "Epoch 58/250\n",
      "637/637 [==============================] - 0s 88us/step - loss: 0.3058 - MAE: 85.1650\n",
      "Epoch 59/250\n",
      "637/637 [==============================] - 0s 53us/step - loss: 0.3088 - MAE: 84.8014\n",
      "Epoch 60/250\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.2917 - MAE: 84.36 - 0s 93us/step - loss: 0.3064 - MAE: 84.7392\n",
      "Epoch 61/250\n",
      "637/637 [==============================] - 0s 48us/step - loss: 0.3069 - MAE: 85.5714\n",
      "Epoch 62/250\n",
      "637/637 [==============================] - 0s 55us/step - loss: 0.3052 - MAE: 84.3140\n",
      "Epoch 63/250\n",
      "637/637 [==============================] - 0s 64us/step - loss: 0.3045 - MAE: 84.7378\n",
      "Epoch 64/250\n",
      "637/637 [==============================] - 0s 56us/step - loss: 0.3020 - MAE: 84.4239\n",
      "Epoch 65/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.3011 - MAE: 84.5349\n",
      "Epoch 66/250\n",
      "637/637 [==============================] - 0s 64us/step - loss: 0.3078 - MAE: 86.1816\n",
      "Epoch 67/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.3075 - MAE: 84.1593\n",
      "Epoch 68/250\n",
      "637/637 [==============================] - 0s 93us/step - loss: 0.3035 - MAE: 84.3178\n",
      "Epoch 69/250\n",
      "637/637 [==============================] - 0s 53us/step - loss: 0.3083 - MAE: 84.8721\n",
      "Epoch 70/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2992 - MAE: 84.4316\n",
      "Epoch 71/250\n",
      "637/637 [==============================] - 0s 63us/step - loss: 0.3025 - MAE: 83.9464\n",
      "Epoch 72/250\n",
      "637/637 [==============================] - 0s 80us/step - loss: 0.3026 - MAE: 84.2404\n",
      "Epoch 73/250\n",
      "637/637 [==============================] - 0s 64us/step - loss: 0.2975 - MAE: 83.6960\n",
      "Epoch 74/250\n",
      "637/637 [==============================] - 0s 94us/step - loss: 0.3006 - MAE: 84.1229\n",
      "Epoch 75/250\n",
      "637/637 [==============================] - 0s 50us/step - loss: 0.2975 - MAE: 83.3848\n",
      "Epoch 76/250\n",
      "637/637 [==============================] - 0s 71us/step - loss: 0.2996 - MAE: 84.0993\n",
      "Epoch 77/250\n",
      "637/637 [==============================] - 0s 51us/step - loss: 0.2962 - MAE: 83.6631\n",
      "Epoch 78/250\n",
      "637/637 [==============================] - 0s 77us/step - loss: 0.2962 - MAE: 83.3060\n",
      "Epoch 79/250\n",
      "637/637 [==============================] - 0s 85us/step - loss: 0.2989 - MAE: 83.3558\n",
      "Epoch 80/250\n",
      "637/637 [==============================] - 0s 52us/step - loss: 0.2968 - MAE: 83.4209\n",
      "Epoch 81/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2944 - MAE: 82.9718\n",
      "Epoch 82/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.2944 - MAE: 82.2252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/250\n",
      "637/637 [==============================] - 0s 95us/step - loss: 0.2985 - MAE: 83.9120\n",
      "Epoch 84/250\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.1801 - MAE: 41.14 - 0s 52us/step - loss: 0.2929 - MAE: 83.8712\n",
      "Epoch 85/250\n",
      "637/637 [==============================] - 0s 77us/step - loss: 0.3039 - MAE: 83.6289\n",
      "Epoch 86/250\n",
      "637/637 [==============================] - 0s 89us/step - loss: 0.2958 - MAE: 82.9858\n",
      "Epoch 87/250\n",
      "637/637 [==============================] - 0s 56us/step - loss: 0.2950 - MAE: 83.3289\n",
      "Epoch 88/250\n",
      "637/637 [==============================] - 0s 88us/step - loss: 0.2970 - MAE: 83.6763\n",
      "Epoch 89/250\n",
      "637/637 [==============================] - 0s 52us/step - loss: 0.2904 - MAE: 82.1587\n",
      "Epoch 90/250\n",
      "637/637 [==============================] - 0s 92us/step - loss: 0.2901 - MAE: 83.1593\n",
      "Epoch 91/250\n",
      "637/637 [==============================] - 0s 52us/step - loss: 0.2892 - MAE: 82.0272\n",
      "Epoch 92/250\n",
      "637/637 [==============================] - 0s 96us/step - loss: 0.2918 - MAE: 82.6415\n",
      "Epoch 93/250\n",
      "637/637 [==============================] - 0s 71us/step - loss: 0.2934 - MAE: 82.9803\n",
      "Epoch 94/250\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.2685 - MAE: 57.05 - 0s 55us/step - loss: 0.2865 - MAE: 82.2125\n",
      "Epoch 95/250\n",
      "637/637 [==============================] - 0s 80us/step - loss: 0.2906 - MAE: 82.3935\n",
      "Epoch 96/250\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.2755 - MAE: 96.25 - 0s 64us/step - loss: 0.2875 - MAE: 81.8115\n",
      "Epoch 97/250\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.3314 - MAE: 123.994 - 0s 94us/step - loss: 0.2905 - MAE: 82.6805\n",
      "Epoch 98/250\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.2866 - MAE: 82.4501\n",
      "Epoch 99/250\n",
      "637/637 [==============================] - 0s 79us/step - loss: 0.2856 - MAE: 82.0095\n",
      "Epoch 100/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.2928 - MAE: 82.4459\n",
      "Epoch 101/250\n",
      "637/637 [==============================] - 0s 94us/step - loss: 0.2849 - MAE: 81.9982\n",
      "Epoch 102/250\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.2922 - MAE: 82.9202\n",
      "Epoch 103/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2853 - MAE: 81.5906\n",
      "Epoch 104/250\n",
      "637/637 [==============================] - 0s 88us/step - loss: 0.2903 - MAE: 82.7940\n",
      "Epoch 105/250\n",
      "637/637 [==============================] - 0s 57us/step - loss: 0.2852 - MAE: 81.6195\n",
      "Epoch 106/250\n",
      "637/637 [==============================] - 0s 77us/step - loss: 0.2876 - MAE: 82.0290\n",
      "Epoch 107/250\n",
      "637/637 [==============================] - 0s 67us/step - loss: 0.2869 - MAE: 82.2956\n",
      "Epoch 108/250\n",
      "637/637 [==============================] - 0s 87us/step - loss: 0.2936 - MAE: 82.9715\n",
      "Epoch 109/250\n",
      "637/637 [==============================] - 0s 55us/step - loss: 0.2820 - MAE: 80.4049\n",
      "Epoch 110/250\n",
      "637/637 [==============================] - 0s 90us/step - loss: 0.2929 - MAE: 82.8154\n",
      "Epoch 111/250\n",
      "637/637 [==============================] - 0s 50us/step - loss: 0.2885 - MAE: 82.6814\n",
      "Epoch 112/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.2893 - MAE: 81.1182\n",
      "Epoch 113/250\n",
      "637/637 [==============================] - 0s 80us/step - loss: 0.2874 - MAE: 82.1329\n",
      "Epoch 114/250\n",
      "637/637 [==============================] - 0s 64us/step - loss: 0.2836 - MAE: 81.4760\n",
      "Epoch 115/250\n",
      "637/637 [==============================] - 0s 81us/step - loss: 0.2860 - MAE: 80.8245\n",
      "Epoch 116/250\n",
      "637/637 [==============================] - 0s 63us/step - loss: 0.2827 - MAE: 81.6741\n",
      "Epoch 117/250\n",
      "637/637 [==============================] - 0s 77us/step - loss: 0.2831 - MAE: 80.7593\n",
      "Epoch 118/250\n",
      "637/637 [==============================] - 0s 56us/step - loss: 0.2825 - MAE: 80.8583\n",
      "Epoch 119/250\n",
      "637/637 [==============================] - 0s 77us/step - loss: 0.2849 - MAE: 81.4764\n",
      "Epoch 120/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.2827 - MAE: 81.5853\n",
      "Epoch 121/250\n",
      "637/637 [==============================] - 0s 92us/step - loss: 0.2829 - MAE: 80.8332\n",
      "Epoch 122/250\n",
      "637/637 [==============================] - 0s 52us/step - loss: 0.2833 - MAE: 82.0738\n",
      "Epoch 123/250\n",
      "637/637 [==============================] - 0s 94us/step - loss: 0.2852 - MAE: 81.9728\n",
      "Epoch 124/250\n",
      "637/637 [==============================] - 0s 60us/step - loss: 0.2796 - MAE: 80.2572\n",
      "Epoch 125/250\n",
      "637/637 [==============================] - 0s 67us/step - loss: 0.2824 - MAE: 81.4617\n",
      "Epoch 126/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2810 - MAE: 81.5467\n",
      "Epoch 127/250\n",
      "637/637 [==============================] - 0s 63us/step - loss: 0.2845 - MAE: 81.4521\n",
      "Epoch 128/250\n",
      "637/637 [==============================] - 0s 81us/step - loss: 0.2821 - MAE: 80.6752\n",
      "Epoch 129/250\n",
      "637/637 [==============================] - 0s 63us/step - loss: 0.2849 - MAE: 81.3465\n",
      "Epoch 130/250\n",
      "637/637 [==============================] - 0s 57us/step - loss: 0.2822 - MAE: 80.7548\n",
      "Epoch 131/250\n",
      "637/637 [==============================] - 0s 77us/step - loss: 0.2791 - MAE: 80.7526\n",
      "Epoch 132/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.2770 - MAE: 80.5736\n",
      "Epoch 133/250\n",
      "637/637 [==============================] - 0s 77us/step - loss: 0.2817 - MAE: 80.0038\n",
      "Epoch 134/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.2776 - MAE: 81.1057\n",
      "Epoch 135/250\n",
      "637/637 [==============================] - 0s 91us/step - loss: 0.2787 - MAE: 80.5594\n",
      "Epoch 136/250\n",
      "637/637 [==============================] - 0s 51us/step - loss: 0.2796 - MAE: 80.7374\n",
      "Epoch 137/250\n",
      "637/637 [==============================] - 0s 93us/step - loss: 0.2788 - MAE: 80.9619\n",
      "Epoch 138/250\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.3041 - MAE: 33.61 - 0s 51us/step - loss: 0.2776 - MAE: 80.2899\n",
      "Epoch 139/250\n",
      "637/637 [==============================] - 0s 79us/step - loss: 0.2809 - MAE: 80.7444\n",
      "Epoch 140/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.2761 - MAE: 80.1287\n",
      "Epoch 141/250\n",
      "637/637 [==============================] - 0s 94us/step - loss: 0.2813 - MAE: 80.7555\n",
      "Epoch 142/250\n",
      "637/637 [==============================] - 0s 51us/step - loss: 0.2775 - MAE: 80.4286\n",
      "Epoch 143/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2788 - MAE: 80.2222\n",
      "Epoch 144/250\n",
      "637/637 [==============================] - 0s 64us/step - loss: 0.2755 - MAE: 80.0924\n",
      "Epoch 145/250\n",
      "637/637 [==============================] - 0s 95us/step - loss: 0.2794 - MAE: 80.0600\n",
      "Epoch 146/250\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.2753 - MAE: 80.4307\n",
      "Epoch 147/250\n",
      "637/637 [==============================] - 0s 94us/step - loss: 0.2781 - MAE: 80.7321\n",
      "Epoch 148/250\n",
      "637/637 [==============================] - 0s 50us/step - loss: 0.2794 - MAE: 80.2336\n",
      "Epoch 149/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2756 - MAE: 79.3216\n",
      "Epoch 150/250\n",
      "637/637 [==============================] - 0s 64us/step - loss: 0.2744 - MAE: 80.6951\n",
      "Epoch 151/250\n",
      "637/637 [==============================] - 0s 80us/step - loss: 0.2777 - MAE: 79.5320\n",
      "Epoch 152/250\n",
      "637/637 [==============================] - 0s 88us/step - loss: 0.2723 - MAE: 79.5544\n",
      "Epoch 153/250\n",
      "637/637 [==============================] - 0s 57us/step - loss: 0.2774 - MAE: 80.2833\n",
      "Epoch 154/250\n",
      "637/637 [==============================] - 0s 77us/step - loss: 0.2732 - MAE: 78.7824\n",
      "Epoch 155/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.2736 - MAE: 79.7946\n",
      "Epoch 156/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2751 - MAE: 80.0211\n",
      "Epoch 157/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.2743 - MAE: 79.7117\n",
      "Epoch 158/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2757 - MAE: 80.2585\n",
      "Epoch 159/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.2714 - MAE: 79.1478\n",
      "Epoch 160/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2709 - MAE: 80.6412\n",
      "Epoch 161/250\n",
      "637/637 [==============================] - 0s 64us/step - loss: 0.2760 - MAE: 79.1872\n",
      "Epoch 162/250\n",
      "637/637 [==============================] - 0s 94us/step - loss: 0.2741 - MAE: 80.0896\n",
      "Epoch 163/250\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.2741 - MAE: 79.4888\n",
      "Epoch 164/250\n",
      "637/637 [==============================] - 0s 80us/step - loss: 0.2736 - MAE: 79.8059\n",
      "Epoch 165/250\n",
      "637/637 [==============================] - 0s 64us/step - loss: 0.2731 - MAE: 79.1031\n",
      "Epoch 166/250\n",
      "637/637 [==============================] - 0s 92us/step - loss: 0.2669 - MAE: 79.6573\n",
      "Epoch 167/250\n",
      "637/637 [==============================] - 0s 53us/step - loss: 0.2767 - MAE: 79.5758\n",
      "Epoch 168/250\n",
      "637/637 [==============================] - 0s 87us/step - loss: 0.2712 - MAE: 79.3929\n",
      "Epoch 169/250\n",
      "637/637 [==============================] - 0s 56us/step - loss: 0.2698 - MAE: 79.0669\n",
      "Epoch 170/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2709 - MAE: 80.2645\n",
      "Epoch 171/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.2712 - MAE: 78.7910\n",
      "Epoch 172/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2737 - MAE: 79.5790\n",
      "Epoch 173/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.2718 - MAE: 79.4386\n",
      "Epoch 174/250\n",
      "637/637 [==============================] - 0s 92us/step - loss: 0.2682 - MAE: 78.3639\n",
      "Epoch 175/250\n",
      "637/637 [==============================] - 0s 61us/step - loss: 0.2695 - MAE: 79.5851\n",
      "Epoch 176/250\n",
      "637/637 [==============================] - 0s 84us/step - loss: 0.2701 - MAE: 79.0774\n",
      "Epoch 177/250\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.2708 - MAE: 78.3755\n",
      "Epoch 178/250\n",
      "637/637 [==============================] - 0s 95us/step - loss: 0.2690 - MAE: 79.7141\n",
      "Epoch 179/250\n",
      "637/637 [==============================] - 0s 60us/step - loss: 0.2724 - MAE: 78.7552\n",
      "Epoch 180/250\n",
      "637/637 [==============================] - 0s 67us/step - loss: 0.2700 - MAE: 79.4239\n",
      "Epoch 181/250\n",
      "637/637 [==============================] - 0s 91us/step - loss: 0.2773 - MAE: 79.9650\n",
      "Epoch 182/250\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.2727 - MAE: 78.6852\n",
      "Epoch 183/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.2723 - MAE: 79.2186\n",
      "Epoch 184/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.2757 - MAE: 79.1976\n",
      "Epoch 185/250\n",
      "637/637 [==============================] - 0s 57us/step - loss: 0.2756 - MAE: 80.1496\n",
      "Epoch 186/250\n",
      "637/637 [==============================] - 0s 87us/step - loss: 0.2704 - MAE: 79.1834\n",
      "Epoch 187/250\n",
      "637/637 [==============================] - 0s 56us/step - loss: 0.2684 - MAE: 78.1682\n",
      "Epoch 188/250\n",
      "637/637 [==============================] - 0s 63us/step - loss: 0.2733 - MAE: 79.5405\n",
      "Epoch 189/250\n",
      "637/637 [==============================] - 0s 56us/step - loss: 0.2728 - MAE: 78.4310\n",
      "Epoch 190/250\n",
      "637/637 [==============================] - 0s 88us/step - loss: 0.2695 - MAE: 78.7797\n",
      "Epoch 191/250\n",
      "637/637 [==============================] - 0s 55us/step - loss: 0.2731 - MAE: 79.2639\n",
      "Epoch 192/250\n",
      "637/637 [==============================] - 0s 90us/step - loss: 0.2679 - MAE: 78.3275\n",
      "Epoch 193/250\n",
      "637/637 [==============================] - 0s 52us/step - loss: 0.2674 - MAE: 78.7650\n",
      "Epoch 194/250\n",
      "637/637 [==============================] - 0s 91us/step - loss: 0.2688 - MAE: 78.5392\n",
      "Epoch 195/250\n",
      "637/637 [==============================] - 0s 50us/step - loss: 0.2661 - MAE: 78.5041\n",
      "Epoch 196/250\n",
      "637/637 [==============================] - 0s 94us/step - loss: 0.2715 - MAE: 79.5169\n",
      "Epoch 197/250\n",
      "637/637 [==============================] - 0s 60us/step - loss: 0.2660 - MAE: 78.1969\n",
      "Epoch 198/250\n",
      "637/637 [==============================] - 0s 83us/step - loss: 0.2668 - MAE: 78.5191\n",
      "Epoch 199/250\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.2666 - MAE: 78.9045\n",
      "Epoch 200/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2633 - MAE: 77.8190\n",
      "Epoch 201/250\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.1328 - MAE: 32.06 - 0s 66us/step - loss: 0.2687 - MAE: 78.4945\n",
      "Epoch 202/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2657 - MAE: 78.4781\n",
      "Epoch 203/250\n",
      "637/637 [==============================] - 0s 64us/step - loss: 0.2655 - MAE: 78.0729\n",
      "Epoch 204/250\n",
      "637/637 [==============================] - 0s 94us/step - loss: 0.2692 - MAE: 79.9200\n",
      "Epoch 205/250\n",
      "637/637 [==============================] - 0s 50us/step - loss: 0.2655 - MAE: 78.8295\n",
      "Epoch 206/250\n",
      "637/637 [==============================] - 0s 80us/step - loss: 0.2655 - MAE: 78.0856\n",
      "Epoch 207/250\n",
      "637/637 [==============================] - 0s 87us/step - loss: 0.2641 - MAE: 77.8102\n",
      "Epoch 208/250\n",
      "637/637 [==============================] - 0s 57us/step - loss: 0.2733 - MAE: 79.1891\n",
      "Epoch 209/250\n",
      "637/637 [==============================] - 0s 63us/step - loss: 0.2693 - MAE: 78.4736\n",
      "Epoch 210/250\n",
      "637/637 [==============================] - 0s 92us/step - loss: 0.2636 - MAE: 77.7306\n",
      "Epoch 211/250\n",
      "637/637 [==============================] - 0s 52us/step - loss: 0.2637 - MAE: 78.0665\n",
      "Epoch 212/250\n",
      "637/637 [==============================] - 0s 90us/step - loss: 0.2675 - MAE: 78.8036\n",
      "Epoch 213/250\n",
      "637/637 [==============================] - 0s 50us/step - loss: 0.2642 - MAE: 78.0331\n",
      "Epoch 214/250\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.1241 - MAE: 71.62 - 0s 94us/step - loss: 0.2694 - MAE: 77.6578\n",
      "Epoch 215/250\n",
      "637/637 [==============================] - 0s 50us/step - loss: 0.2636 - MAE: 78.1670\n",
      "Epoch 216/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2639 - MAE: 77.8183\n",
      "Epoch 217/250\n",
      "637/637 [==============================] - 0s 64us/step - loss: 0.2677 - MAE: 78.0050\n",
      "Epoch 218/250\n",
      "637/637 [==============================] - 0s 80us/step - loss: 0.2663 - MAE: 78.1174\n",
      "Epoch 219/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2685 - MAE: 78.7038\n",
      "Epoch 220/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.2652 - MAE: 78.7039\n",
      "Epoch 221/250\n",
      "637/637 [==============================] - 0s 64us/step - loss: 0.2632 - MAE: 77.7160\n",
      "Epoch 222/250\n",
      "637/637 [==============================] - 0s 94us/step - loss: 0.2630 - MAE: 78.3355\n",
      "Epoch 223/250\n",
      "637/637 [==============================] - 0s 50us/step - loss: 0.2695 - MAE: 79.1832\n",
      "Epoch 224/250\n",
      "637/637 [==============================] - 0s 95us/step - loss: 0.2636 - MAE: 77.7747\n",
      "Epoch 225/250\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.2639 - MAE: 78.4194\n",
      "Epoch 226/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2664 - MAE: 78.3958\n",
      "Epoch 227/250\n",
      "637/637 [==============================] - 0s 77us/step - loss: 0.2620 - MAE: 77.2512\n",
      "Epoch 228/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.2617 - MAE: 77.2954\n",
      "Epoch 229/250\n",
      "637/637 [==============================] - 0s 56us/step - loss: 0.2617 - MAE: 77.5922\n",
      "Epoch 230/250\n",
      "637/637 [==============================] - 0s 65us/step - loss: 0.2623 - MAE: 77.0191\n",
      "Epoch 231/250\n",
      "637/637 [==============================] - 0s 64us/step - loss: 0.2633 - MAE: 77.9376\n",
      "Epoch 232/250\n",
      "637/637 [==============================] - 0s 81us/step - loss: 0.2625 - MAE: 77.6804\n",
      "Epoch 233/250\n",
      "637/637 [==============================] - 0s 77us/step - loss: 0.2621 - MAE: 77.9782\n",
      "Epoch 234/250\n",
      "637/637 [==============================] - 0s 66us/step - loss: 0.2665 - MAE: 78.1183\n",
      "Epoch 235/250\n",
      "637/637 [==============================] - 0s 88us/step - loss: 0.2695 - MAE: 78.3614\n",
      "Epoch 236/250\n",
      "637/637 [==============================] - 0s 52us/step - loss: 0.2586 - MAE: 77.8618\n",
      "Epoch 237/250\n",
      "637/637 [==============================] - 0s 93us/step - loss: 0.2658 - MAE: 78.5777\n",
      "Epoch 238/250\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.7021 - MAE: 184.119 - 0s 51us/step - loss: 0.2612 - MAE: 77.1894\n",
      "Epoch 239/250\n",
      "637/637 [==============================] - 0s 81us/step - loss: 0.2656 - MAE: 79.1521\n",
      "Epoch 240/250\n",
      "637/637 [==============================] - 0s 63us/step - loss: 0.2597 - MAE: 77.5813\n",
      "Epoch 241/250\n",
      "637/637 [==============================] - 0s 95us/step - loss: 0.2619 - MAE: 77.8506\n",
      "Epoch 242/250\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.2610 - MAE: 77.2650\n",
      "Epoch 243/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637/637 [==============================] - 0s 95us/step - loss: 0.2598 - MAE: 77.7107\n",
      "Epoch 244/250\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2641 - MAE: 77.6882\n",
      "Epoch 245/250\n",
      "637/637 [==============================] - 0s 56us/step - loss: 0.2613 - MAE: 77.3656\n",
      "Epoch 246/250\n",
      "637/637 [==============================] - 0s 88us/step - loss: 0.2649 - MAE: 77.4468\n",
      "Epoch 247/250\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.2595 - MAE: 109.186 - 0s 55us/step - loss: 0.2609 - MAE: 77.1575\n",
      "Epoch 248/250\n",
      "637/637 [==============================] - 0s 89us/step - loss: 0.2567 - MAE: 76.8054\n",
      "Epoch 249/250\n",
      "637/637 [==============================] - 0s 56us/step - loss: 0.2650 - MAE: 78.1585\n",
      "Epoch 250/250\n",
      "637/637 [==============================] - 0s 78us/step - loss: 0.2615 - MAE: 77.7274\n",
      "실제관객:111.052, 예상관객 :105.132\n",
      "실제관객:151.536, 예상관객 :106.437\n",
      "실제관객:46.770, 예상관객 :46.458\n",
      "실제관객:243.410, 예상관객 :192.181\n",
      "실제관객:30.601, 예상관객 :25.598\n",
      "실제관객:50.962, 예상관객 :48.639\n",
      "실제관객:639.653, 예상관객 :243.290\n",
      "실제관객:34.488, 예상관객 :48.030\n",
      "실제관객:171.480, 예상관객 :211.280\n",
      "실제관객:70.973, 예상관객 :104.733\n",
      "213/213 [==============================] - 0s 93us/step\n",
      "\n",
      " Accuracy: 88.3130\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "df = pd.read_excel('./res/데이터/movie_score.xlsx')\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:, 2:8]\n",
    "Y = dataset[:, 1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=6, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['MAE'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=250, batch_size=10)\n",
    "\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    label = Y_test[i].astype(float)\n",
    "    prediction = Y_prediction[i].astype(float)\n",
    "    print(\"실제관객:%.3f, 예상관객 :%.3f\"%(label, prediction))\n",
    "    \n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k겹 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Bigdata\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "425/425 [==============================] - 0s 243us/step - loss: 170532.5059 - MAE: 350.1959\n",
      "Epoch 2/250\n",
      "425/425 [==============================] - 0s 62us/step - loss: 80510.8796 - MAE: 232.2076\n",
      "Epoch 3/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 35787.8114 - MAE: 153.7552\n",
      "Epoch 4/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 33403.9193 - MAE: 147.5245\n",
      "Epoch 5/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 32761.0431 - MAE: 146.2305\n",
      "Epoch 6/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 32320.4107 - MAE: 145.2092\n",
      "Epoch 7/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 31942.4101 - MAE: 144.7140\n",
      "Epoch 8/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 19710.8281 - MAE: 128.774 - 0s 62us/step - loss: 31377.1519 - MAE: 143.4901\n",
      "Epoch 9/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 30875.9669 - MAE: 142.5695\n",
      "Epoch 10/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 30415.6214 - MAE: 141.3496\n",
      "Epoch 11/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 29904.8601 - MAE: 139.9736\n",
      "Epoch 12/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 32194.8594 - MAE: 146.064 - 0s 63us/step - loss: 29561.4610 - MAE: 139.8493\n",
      "Epoch 13/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 29104.8986 - MAE: 138.7689\n",
      "Epoch 14/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 28615.7783 - MAE: 137.3070\n",
      "Epoch 15/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 28388.9908 - MAE: 136.8249\n",
      "Epoch 16/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 27892.9221 - MAE: 135.9932\n",
      "Epoch 17/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 27628.8004 - MAE: 135.4106\n",
      "Epoch 18/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 27034.9752 - MAE: 133.8934\n",
      "Epoch 19/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 26774.3423 - MAE: 133.3339\n",
      "Epoch 20/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 26562.1536 - MAE: 133.1679\n",
      "Epoch 21/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 26158.0542 - MAE: 131.5531\n",
      "Epoch 22/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 25781.3610 - MAE: 130.9370\n",
      "Epoch 23/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 25456.5571 - MAE: 129.7307\n",
      "Epoch 24/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 25193.2946 - MAE: 129.1992\n",
      "Epoch 25/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 24924.4715 - MAE: 128.0914\n",
      "Epoch 26/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 24723.9704 - MAE: 127.5544\n",
      "Epoch 27/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 34923.4609 - MAE: 166.949 - 0s 63us/step - loss: 24219.9946 - MAE: 125.6714\n",
      "Epoch 28/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 24236.9118 - MAE: 126.6271\n",
      "Epoch 29/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 23915.4067 - MAE: 125.7923\n",
      "Epoch 30/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 23601.9449 - MAE: 123.7140\n",
      "Epoch 31/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 23259.6144 - MAE: 123.1078\n",
      "Epoch 32/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 23147.2916 - MAE: 122.5286\n",
      "Epoch 33/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 22897.6442 - MAE: 121.6692\n",
      "Epoch 34/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 22468.9518 - MAE: 120.9888\n",
      "Epoch 35/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 22275.7076 - MAE: 119.8186\n",
      "Epoch 36/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 22105.1807 - MAE: 119.2548\n",
      "Epoch 37/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 21912.1985 - MAE: 118.5805\n",
      "Epoch 38/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 21505.5306 - MAE: 117.2317\n",
      "Epoch 39/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 21591.0076 - MAE: 117.2419\n",
      "Epoch 40/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 21509.2017 - MAE: 116.5295\n",
      "Epoch 41/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 21009.2570 - MAE: 114.9605\n",
      "Epoch 42/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 20840.4120 - MAE: 114.4377\n",
      "Epoch 43/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 20644.9704 - MAE: 113.0747\n",
      "Epoch 44/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 20531.3664 - MAE: 113.6060\n",
      "Epoch 45/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 20383.7363 - MAE: 111.9780\n",
      "Epoch 46/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 20115.2043 - MAE: 110.9674\n",
      "Epoch 47/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 19910.4824 - MAE: 110.8388\n",
      "Epoch 48/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 19952.4016 - MAE: 110.5774\n",
      "Epoch 49/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 20216.0819 - MAE: 110.6623\n",
      "Epoch 50/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 19815.1547 - MAE: 109.9720\n",
      "Epoch 51/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 19727.4030 - MAE: 109.3342\n",
      "Epoch 52/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 19420.4795 - MAE: 108.4974\n",
      "Epoch 53/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 19487.7930 - MAE: 108.4175\n",
      "Epoch 54/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 19257.6208 - MAE: 107.1816\n",
      "Epoch 55/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 19202.7999 - MAE: 106.7642\n",
      "Epoch 56/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 19336.9124 - MAE: 106.7967\n",
      "Epoch 57/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 19553.6339 - MAE: 108.4613\n",
      "Epoch 58/250\n",
      "425/425 [==============================] - 0s 67us/step - loss: 18975.4334 - MAE: 105.4767\n",
      "Epoch 59/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 19234.5725 - MAE: 106.8492\n",
      "Epoch 60/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 19358.6290 - MAE: 108.4685\n",
      "Epoch 61/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18904.8340 - MAE: 105.1484\n",
      "Epoch 62/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 18917.6437 - MAE: 105.8549\n",
      "Epoch 63/250\n",
      "425/425 [==============================] - 0s 62us/step - loss: 18799.1966 - MAE: 104.9792\n",
      "Epoch 64/250\n",
      "425/425 [==============================] - 0s 56us/step - loss: 18861.9499 - MAE: 106.0823\n",
      "Epoch 65/250\n",
      "425/425 [==============================] - 0s 59us/step - loss: 18896.1581 - MAE: 104.2309\n",
      "Epoch 66/250\n",
      "425/425 [==============================] - 0s 62us/step - loss: 18740.3796 - MAE: 104.5990\n",
      "Epoch 67/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 19169.1475 - MAE: 106.2306\n",
      "Epoch 68/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 19253.4163 - MAE: 107.7154\n",
      "Epoch 69/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 18630.5115 - MAE: 104.7538\n",
      "Epoch 70/250\n",
      "425/425 [==============================] - 0s 67us/step - loss: 19007.0551 - MAE: 105.2719\n",
      "Epoch 71/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 18708.1142 - MAE: 104.6903\n",
      "Epoch 72/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18634.3761 - MAE: 103.6436\n",
      "Epoch 73/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18748.9574 - MAE: 103.8568\n",
      "Epoch 74/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 18651.9439 - MAE: 103.5730\n",
      "Epoch 75/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18717.5047 - MAE: 104.9101\n",
      "Epoch 76/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18518.8389 - MAE: 103.4175\n",
      "Epoch 77/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18600.3820 - MAE: 103.5654\n",
      "Epoch 78/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18585.4835 - MAE: 104.6422\n",
      "Epoch 79/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18434.0260 - MAE: 103.0380\n",
      "Epoch 80/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18347.2018 - MAE: 102.5150\n",
      "Epoch 81/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18613.6353 - MAE: 103.3783\n",
      "Epoch 82/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18303.5258 - MAE: 102.5166\n",
      "Epoch 83/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 18518.9965 - MAE: 104.0609\n",
      "Epoch 84/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 18361.0706 - MAE: 102.2303\n",
      "Epoch 85/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18450.8742 - MAE: 103.2090\n",
      "Epoch 86/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18415.9158 - MAE: 103.5460\n",
      "Epoch 87/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18371.7301 - MAE: 101.8328\n",
      "Epoch 88/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18570.1608 - MAE: 102.4897\n",
      "Epoch 89/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 18287.5389 - MAE: 102.7986\n",
      "Epoch 90/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18294.9787 - MAE: 103.1522\n",
      "Epoch 91/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18388.0756 - MAE: 103.0361\n",
      "Epoch 92/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18484.8127 - MAE: 102.2616\n",
      "Epoch 93/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18237.8628 - MAE: 102.7809\n",
      "Epoch 94/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18259.2394 - MAE: 102.4728\n",
      "Epoch 95/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 18413.9792 - MAE: 103.2387\n",
      "Epoch 96/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18834.2569 - MAE: 101.8925\n",
      "Epoch 97/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18095.5986 - MAE: 103.8445\n",
      "Epoch 98/250\n",
      "425/425 [==============================] - 0s 62us/step - loss: 18456.9890 - MAE: 102.7958\n",
      "Epoch 99/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18433.6209 - MAE: 103.7850\n",
      "Epoch 100/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18224.6221 - MAE: 101.9188\n",
      "Epoch 101/250\n",
      "425/425 [==============================] - 0s 62us/step - loss: 18411.2919 - MAE: 103.3713\n",
      "Epoch 102/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18475.2630 - MAE: 103.5147\n",
      "Epoch 103/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18138.8826 - MAE: 102.7127\n",
      "Epoch 104/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 18655.8669 - MAE: 102.8265\n",
      "Epoch 105/250\n",
      "425/425 [==============================] - 0s 62us/step - loss: 18134.0719 - MAE: 103.0464\n",
      "Epoch 106/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18164.8004 - MAE: 102.8016\n",
      "Epoch 107/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 9642.0166 - MAE: 77.445 - 0s 62us/step - loss: 18279.1433 - MAE: 102.8195\n",
      "Epoch 108/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 18107.4793 - MAE: 102.0319\n",
      "Epoch 109/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18515.3539 - MAE: 104.7459\n",
      "Epoch 110/250\n",
      "425/425 [==============================] - 0s 62us/step - loss: 18269.2291 - MAE: 101.6626\n",
      "Epoch 111/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18221.8189 - MAE: 102.8564\n",
      "Epoch 112/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 18230.7581 - MAE: 102.7989\n",
      "Epoch 113/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18205.6474 - MAE: 100.9820\n",
      "Epoch 114/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 18169.4884 - MAE: 102.6476\n",
      "Epoch 115/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18292.6809 - MAE: 102.8948\n",
      "Epoch 116/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18148.0741 - MAE: 102.4740\n",
      "Epoch 117/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18505.6583 - MAE: 103.3751\n",
      "Epoch 118/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18278.1632 - MAE: 103.2954\n",
      "Epoch 119/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 18282.0802 - MAE: 103.4117\n",
      "Epoch 120/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18365.9329 - MAE: 102.7630\n",
      "Epoch 121/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18051.4888 - MAE: 102.5992\n",
      "Epoch 122/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18527.7991 - MAE: 102.1018\n",
      "Epoch 123/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18209.0706 - MAE: 103.0695\n",
      "Epoch 124/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18226.3537 - MAE: 103.5246\n",
      "Epoch 125/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18247.7565 - MAE: 103.0144\n",
      "Epoch 126/250\n",
      "425/425 [==============================] - 0s 62us/step - loss: 18112.9813 - MAE: 101.6893\n",
      "Epoch 127/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18169.4584 - MAE: 102.7092\n",
      "Epoch 128/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 18188.8375 - MAE: 102.7121\n",
      "Epoch 129/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18153.0818 - MAE: 102.9888\n",
      "Epoch 130/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18242.9243 - MAE: 101.8168\n",
      "Epoch 131/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 18131.5982 - MAE: 102.4748\n",
      "Epoch 132/250\n",
      "425/425 [==============================] - 0s 62us/step - loss: 18034.9595 - MAE: 101.6542\n",
      "Epoch 133/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 18183.8579 - MAE: 102.6549\n",
      "Epoch 134/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 18481.9258 - MAE: 103.4165\n",
      "Epoch 135/250\n",
      "425/425 [==============================] - 0s 62us/step - loss: 18003.6377 - MAE: 102.2311\n",
      "Epoch 136/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18102.4972 - MAE: 102.6678\n",
      "Epoch 137/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 18395.9162 - MAE: 103.1537\n",
      "Epoch 138/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18070.5456 - MAE: 102.2122\n",
      "Epoch 139/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18014.7324 - MAE: 101.9756\n",
      "Epoch 140/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 18039.8599 - MAE: 101.9268\n",
      "Epoch 141/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 9811.3955 - MAE: 73.408 - 0s 61us/step - loss: 18237.6949 - MAE: 103.3447\n",
      "Epoch 142/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 18203.7060 - MAE: 100.7177\n",
      "Epoch 143/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18395.0694 - MAE: 103.9775\n",
      "Epoch 144/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18101.7844 - MAE: 101.5152\n",
      "Epoch 145/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18636.4184 - MAE: 105.4891\n",
      "Epoch 146/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 17965.7110 - MAE: 101.3930\n",
      "Epoch 147/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18120.3139 - MAE: 101.8773\n",
      "Epoch 148/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18099.7529 - MAE: 101.6006\n",
      "Epoch 149/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18118.7076 - MAE: 102.5256\n",
      "Epoch 150/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18331.4086 - MAE: 103.2074\n",
      "Epoch 151/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 17905.2934 - MAE: 103.0114\n",
      "Epoch 152/250\n",
      "425/425 [==============================] - 0s 62us/step - loss: 18191.5585 - MAE: 103.6447\n",
      "Epoch 153/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 18089.8616 - MAE: 103.2028\n",
      "Epoch 154/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18125.5427 - MAE: 101.4287\n",
      "Epoch 155/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425/425 [==============================] - 0s 60us/step - loss: 18417.6175 - MAE: 103.1270\n",
      "Epoch 156/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 18021.4986 - MAE: 100.7262\n",
      "Epoch 157/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18059.7682 - MAE: 102.3445\n",
      "Epoch 158/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17959.7773 - MAE: 102.2444\n",
      "Epoch 159/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17949.9867 - MAE: 101.5165\n",
      "Epoch 160/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18327.9600 - MAE: 102.0881\n",
      "Epoch 161/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18021.0864 - MAE: 102.6010\n",
      "Epoch 162/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18097.1441 - MAE: 102.1880\n",
      "Epoch 163/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18088.1045 - MAE: 102.0203\n",
      "Epoch 164/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 18171.6179 - MAE: 103.1793\n",
      "Epoch 165/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 18040.2556 - MAE: 102.0612\n",
      "Epoch 166/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17844.4504 - MAE: 100.9067\n",
      "Epoch 167/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 18157.1875 - MAE: 102.6404\n",
      "Epoch 168/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17902.1274 - MAE: 101.7726\n",
      "Epoch 169/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 18102.4059 - MAE: 101.8325\n",
      "Epoch 170/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18075.9467 - MAE: 102.2797\n",
      "Epoch 171/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18054.5776 - MAE: 101.5218\n",
      "Epoch 172/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 17989.8046 - MAE: 102.0189\n",
      "Epoch 173/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18132.8250 - MAE: 102.1113\n",
      "Epoch 174/250\n",
      "425/425 [==============================] - 0s 59us/step - loss: 18391.6490 - MAE: 103.9455\n",
      "Epoch 175/250\n",
      "425/425 [==============================] - 0s 56us/step - loss: 17885.9796 - MAE: 100.9143\n",
      "Epoch 176/250\n",
      "425/425 [==============================] - 0s 56us/step - loss: 17925.7622 - MAE: 101.6742\n",
      "Epoch 177/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 17954.0777 - MAE: 101.0190\n",
      "Epoch 178/250\n",
      "425/425 [==============================] - 0s 58us/step - loss: 18013.5355 - MAE: 102.7965\n",
      "Epoch 179/250\n",
      "425/425 [==============================] - 0s 62us/step - loss: 17831.4923 - MAE: 101.6032\n",
      "Epoch 180/250\n",
      "425/425 [==============================] - 0s 59us/step - loss: 17801.8474 - MAE: 101.1440\n",
      "Epoch 181/250\n",
      "425/425 [==============================] - 0s 60us/step - loss: 18082.9031 - MAE: 102.2435\n",
      "Epoch 182/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17965.2786 - MAE: 101.4748\n",
      "Epoch 183/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17841.2578 - MAE: 101.1689\n",
      "Epoch 184/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 18108.3630 - MAE: 102.7125\n",
      "Epoch 185/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 17918.3888 - MAE: 101.0524\n",
      "Epoch 186/250\n",
      "425/425 [==============================] - 0s 62us/step - loss: 18041.0158 - MAE: 102.2398\n",
      "Epoch 187/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17855.2706 - MAE: 100.5393\n",
      "Epoch 188/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 17866.4312 - MAE: 100.5403\n",
      "Epoch 189/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17909.3086 - MAE: 102.1611\n",
      "Epoch 190/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17792.2016 - MAE: 100.9022\n",
      "Epoch 191/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17866.3153 - MAE: 101.3441\n",
      "Epoch 192/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17665.2792 - MAE: 101.0443\n",
      "Epoch 193/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 18184.3781 - MAE: 101.8812\n",
      "Epoch 194/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17848.5344 - MAE: 101.5811\n",
      "Epoch 195/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17715.6415 - MAE: 100.2386\n",
      "Epoch 196/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18068.5608 - MAE: 101.8663\n",
      "Epoch 197/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18047.4822 - MAE: 101.8333\n",
      "Epoch 198/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17661.8128 - MAE: 100.2799\n",
      "Epoch 199/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 17622.9403 - MAE: 99.2362\n",
      "Epoch 200/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17812.0967 - MAE: 100.2402\n",
      "Epoch 201/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17767.9198 - MAE: 102.0915\n",
      "Epoch 202/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 17994.0284 - MAE: 101.5736\n",
      "Epoch 203/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17822.7255 - MAE: 101.0138\n",
      "Epoch 204/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 17673.7962 - MAE: 100.2360\n",
      "Epoch 205/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17582.6991 - MAE: 100.0079\n",
      "Epoch 206/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17609.0761 - MAE: 99.4044\n",
      "Epoch 207/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 17740.7275 - MAE: 102.3414\n",
      "Epoch 208/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 17673.1378 - MAE: 99.5958\n",
      "Epoch 209/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17878.0489 - MAE: 101.2911\n",
      "Epoch 210/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17886.5275 - MAE: 101.0940\n",
      "Epoch 211/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 18086.1848 - MAE: 102.7422\n",
      "Epoch 212/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17698.9341 - MAE: 100.8047\n",
      "Epoch 213/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 18424.7462 - MAE: 101.3424\n",
      "Epoch 214/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17481.0653 - MAE: 99.6482\n",
      "Epoch 215/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 17471.5528 - MAE: 100.0177\n",
      "Epoch 216/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 17341.5196 - MAE: 98.5011\n",
      "Epoch 217/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 17278.5375 - MAE: 98.8484\n",
      "Epoch 218/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17175.0836 - MAE: 97.5307\n",
      "Epoch 219/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17501.4461 - MAE: 99.5183\n",
      "Epoch 220/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17625.7355 - MAE: 100.2495\n",
      "Epoch 221/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 17159.5525 - MAE: 98.3343\n",
      "Epoch 222/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17196.8385 - MAE: 98.2087\n",
      "Epoch 223/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17550.2775 - MAE: 99.6714\n",
      "Epoch 224/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17416.1149 - MAE: 98.4023\n",
      "Epoch 225/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17245.0043 - MAE: 99.2882\n",
      "Epoch 226/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 17508.0361 - MAE: 98.2777\n",
      "Epoch 227/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17015.8663 - MAE: 96.9606\n",
      "Epoch 228/250\n",
      "425/425 [==============================] - 0s 67us/step - loss: 16925.0123 - MAE: 97.9270\n",
      "Epoch 229/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 16920.8731 - MAE: 97.1687\n",
      "Epoch 230/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 17013.3898 - MAE: 96.8565\n",
      "Epoch 231/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 16913.5782 - MAE: 96.6721\n",
      "Epoch 232/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17312.4544 - MAE: 97.2466\n",
      "Epoch 233/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 17236.9385 - MAE: 97.9115\n",
      "Epoch 234/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 16929.1273 - MAE: 97.1237\n",
      "Epoch 235/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 16815.5843 - MAE: 95.5960\n",
      "Epoch 236/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 16610.2435 - MAE: 95.6824\n",
      "Epoch 237/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 16814.0129 - MAE: 96.9080\n",
      "Epoch 238/250\n",
      "425/425 [==============================] - 0s 67us/step - loss: 16849.6024 - MAE: 95.1783\n",
      "Epoch 239/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 17374.9044 - MAE: 98.6161\n",
      "Epoch 240/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 16860.4456 - MAE: 96.4193\n",
      "Epoch 241/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 16641.4631 - MAE: 94.9896\n",
      "Epoch 242/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 16730.6742 - MAE: 95.0625\n",
      "Epoch 243/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 16319.9148 - MAE: 94.3586\n",
      "Epoch 244/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 16359.6761 - MAE: 93.5446\n",
      "Epoch 245/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 16471.8136 - MAE: 93.4987\n",
      "Epoch 246/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 16414.9406 - MAE: 92.8149\n",
      "Epoch 247/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 16512.7227 - MAE: 96.0803\n",
      "Epoch 248/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 16435.1187 - MAE: 92.9174\n",
      "Epoch 249/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 15978.0677 - MAE: 91.4964\n",
      "Epoch 250/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 16550.0179 - MAE: 95.7352\n",
      "425/425 [==============================] - 0s 33us/step\n",
      "Epoch 1/250\n",
      "425/425 [==============================] - 0s 249us/step - loss: 72477.1965 - MAE: 215.3004\n",
      "Epoch 2/250\n",
      "425/425 [==============================] - 0s 80us/step - loss: 34855.4829 - MAE: 151.3007\n",
      "Epoch 3/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 34311.0983 - MAE: 150.1752\n",
      "Epoch 4/250\n",
      "425/425 [==============================] - 0s 61us/step - loss: 33426.2534 - MAE: 148.6376\n",
      "Epoch 5/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 32571.8372 - MAE: 146.3712\n",
      "Epoch 6/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 31658.3514 - MAE: 144.5351\n",
      "Epoch 7/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 30645.3846 - MAE: 143.4387\n",
      "Epoch 8/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 30739.6839 - MAE: 142.6796\n",
      "Epoch 9/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 29153.8476 - MAE: 139.0726\n",
      "Epoch 10/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 28070.9845 - MAE: 136.3338\n",
      "Epoch 11/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 27668.9114 - MAE: 135.6366\n",
      "Epoch 12/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 26379.8513 - MAE: 132.3715\n",
      "Epoch 13/250\n",
      "425/425 [==============================] - 0s 67us/step - loss: 25390.9085 - MAE: 129.7672\n",
      "Epoch 14/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 24392.0741 - MAE: 126.5895\n",
      "Epoch 15/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 23501.8295 - MAE: 124.3942\n",
      "Epoch 16/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 22651.2139 - MAE: 122.3881\n",
      "Epoch 17/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 21697.2687 - MAE: 119.6445\n",
      "Epoch 18/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 20950.4418 - MAE: 117.4859\n",
      "Epoch 19/250\n",
      "425/425 [==============================] - 0s 63us/step - loss: 21132.7003 - MAE: 118.0231\n",
      "Epoch 20/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 29924.0996 - MAE: 152.404 - 0s 68us/step - loss: 19412.3601 - MAE: 112.5997\n",
      "Epoch 21/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 19071.9460 - MAE: 111.9428\n",
      "Epoch 22/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 18387.1957 - MAE: 109.1034\n",
      "Epoch 23/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 17844.1940 - MAE: 107.7425\n",
      "Epoch 24/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 17867.6236 - MAE: 106.3528\n",
      "Epoch 25/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 17488.4252 - MAE: 105.8347\n",
      "Epoch 26/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 17269.9380 - MAE: 104.7750\n",
      "Epoch 27/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 17176.3618 - MAE: 104.2501\n",
      "Epoch 28/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 17100.4352 - MAE: 103.7465\n",
      "Epoch 29/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 17010.5413 - MAE: 103.5718\n",
      "Epoch 30/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16600.9367 - MAE: 102.7009\n",
      "Epoch 31/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16924.8423 - MAE: 103.3300\n",
      "Epoch 32/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16450.6781 - MAE: 101.4437\n",
      "Epoch 33/250\n",
      "425/425 [==============================] - 0s 67us/step - loss: 16672.9864 - MAE: 102.4503\n",
      "Epoch 34/250\n",
      "425/425 [==============================] - 0s 76us/step - loss: 16327.7830 - MAE: 101.7161\n",
      "Epoch 35/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 16620.4114 - MAE: 101.4308\n",
      "Epoch 36/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 16265.8947 - MAE: 101.7704\n",
      "Epoch 37/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16388.0644 - MAE: 101.6915\n",
      "Epoch 38/250\n",
      "425/425 [==============================] - 0s 72us/step - loss: 16756.2903 - MAE: 102.5802\n",
      "Epoch 39/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 16138.5296 - MAE: 100.3239\n",
      "Epoch 40/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 16675.4203 - MAE: 102.7876\n",
      "Epoch 41/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16141.2901 - MAE: 100.0352\n",
      "Epoch 42/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 16476.6549 - MAE: 100.8027\n",
      "Epoch 43/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16178.1124 - MAE: 100.1407\n",
      "Epoch 44/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16172.7477 - MAE: 100.0466\n",
      "Epoch 45/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16110.1048 - MAE: 99.7819\n",
      "Epoch 46/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 16193.6374 - MAE: 100.6651\n",
      "Epoch 47/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 16840.6182 - MAE: 100.4518\n",
      "Epoch 48/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16932.7369 - MAE: 104.4835\n",
      "Epoch 49/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 16307.6024 - MAE: 99.1736\n",
      "Epoch 50/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16645.8553 - MAE: 101.9724\n",
      "Epoch 51/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16140.2461 - MAE: 100.3054\n",
      "Epoch 52/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 15978.4851 - MAE: 100.1693\n",
      "Epoch 53/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16587.0630 - MAE: 101.3150\n",
      "Epoch 54/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 16220.3981 - MAE: 100.7188\n",
      "Epoch 55/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16068.1133 - MAE: 99.9225\n",
      "Epoch 56/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16235.8771 - MAE: 101.0020\n",
      "Epoch 57/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16440.0094 - MAE: 100.0360\n",
      "Epoch 58/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 16437.8110 - MAE: 101.5318\n",
      "Epoch 59/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16455.2734 - MAE: 101.7312\n",
      "Epoch 60/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16573.7030 - MAE: 100.8940\n",
      "Epoch 61/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425/425 [==============================] - 0s 68us/step - loss: 16219.1141 - MAE: 100.4410\n",
      "Epoch 62/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 18402.3574 - MAE: 125.982 - 0s 70us/step - loss: 16372.8076 - MAE: 100.6064\n",
      "Epoch 63/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 19294.2109 - MAE: 106.624 - 0s 70us/step - loss: 15899.0924 - MAE: 99.9349\n",
      "Epoch 64/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 15939.3745 - MAE: 98.2296\n",
      "Epoch 65/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15971.8998 - MAE: 100.2016\n",
      "Epoch 66/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16170.0010 - MAE: 100.2650\n",
      "Epoch 67/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 16414.4771 - MAE: 100.0700\n",
      "Epoch 68/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15930.5757 - MAE: 99.5792\n",
      "Epoch 69/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 15860.1444 - MAE: 98.9382\n",
      "Epoch 70/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 16039.1045 - MAE: 100.2126\n",
      "Epoch 71/250\n",
      "425/425 [==============================] - 0s 74us/step - loss: 16111.3023 - MAE: 99.4286\n",
      "Epoch 72/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16007.8244 - MAE: 99.3486\n",
      "Epoch 73/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16103.8028 - MAE: 100.0133\n",
      "Epoch 74/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15891.7707 - MAE: 98.9098\n",
      "Epoch 75/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15923.3571 - MAE: 100.3087\n",
      "Epoch 76/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16068.6477 - MAE: 99.2954\n",
      "Epoch 77/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15896.2923 - MAE: 99.8540\n",
      "Epoch 78/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15980.0705 - MAE: 99.0705\n",
      "Epoch 79/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 16416.3000 - MAE: 101.0025\n",
      "Epoch 80/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15940.0099 - MAE: 98.6380\n",
      "Epoch 81/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 16038.6104 - MAE: 100.6547\n",
      "Epoch 82/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16223.3823 - MAE: 99.3580\n",
      "Epoch 83/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16295.6191 - MAE: 101.6837\n",
      "Epoch 84/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16017.1249 - MAE: 99.2972\n",
      "Epoch 85/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16175.3737 - MAE: 99.9052\n",
      "Epoch 86/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 15826.3030 - MAE: 98.3576\n",
      "Epoch 87/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16173.9229 - MAE: 100.5083\n",
      "Epoch 88/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 15903.9925 - MAE: 99.2212\n",
      "Epoch 89/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16317.1433 - MAE: 100.4074\n",
      "Epoch 90/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 16185.1583 - MAE: 100.1856\n",
      "Epoch 91/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 15936.0301 - MAE: 98.8989\n",
      "Epoch 92/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15944.2090 - MAE: 99.4344\n",
      "Epoch 93/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 12782.9277 - MAE: 100.103 - 0s 70us/step - loss: 15882.0770 - MAE: 98.3502\n",
      "Epoch 94/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 16047.0566 - MAE: 99.7731\n",
      "Epoch 95/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16290.8277 - MAE: 101.2143\n",
      "Epoch 96/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16474.6058 - MAE: 99.9037\n",
      "Epoch 97/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 16344.4181 - MAE: 101.3458\n",
      "Epoch 98/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15985.5073 - MAE: 99.5550\n",
      "Epoch 99/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16260.6120 - MAE: 100.5367\n",
      "Epoch 100/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 18296.2383 - MAE: 105.493 - 0s 70us/step - loss: 16085.5136 - MAE: 99.2386\n",
      "Epoch 101/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15954.1894 - MAE: 99.3503\n",
      "Epoch 102/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15973.1708 - MAE: 99.8493\n",
      "Epoch 103/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16186.4881 - MAE: 99.1875\n",
      "Epoch 104/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16142.5844 - MAE: 100.9693\n",
      "Epoch 105/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16124.0428 - MAE: 99.3321\n",
      "Epoch 106/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 16046.3496 - MAE: 99.7016\n",
      "Epoch 107/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16618.0190 - MAE: 102.6602\n",
      "Epoch 108/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 16236.5543 - MAE: 101.0389\n",
      "Epoch 109/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15924.8694 - MAE: 99.0072\n",
      "Epoch 110/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 15897.9151 - MAE: 99.0856\n",
      "Epoch 111/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16210.9177 - MAE: 99.8197\n",
      "Epoch 112/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15797.0545 - MAE: 99.1642\n",
      "Epoch 113/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 16065.6474 - MAE: 99.6889\n",
      "Epoch 114/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 15843.7936 - MAE: 98.4078\n",
      "Epoch 115/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 15927.1381 - MAE: 97.9330\n",
      "Epoch 116/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 15583.2198 - MAE: 98.5644\n",
      "Epoch 117/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 15928.0134 - MAE: 99.3696\n",
      "Epoch 118/250\n",
      "425/425 [==============================] - 0s 59us/step - loss: 16261.5364 - MAE: 100.2163\n",
      "Epoch 119/250\n",
      "425/425 [==============================] - 0s 59us/step - loss: 15728.0201 - MAE: 98.9118\n",
      "Epoch 120/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 16012.2658 - MAE: 98.6234\n",
      "Epoch 121/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 15937.1806 - MAE: 99.5835\n",
      "Epoch 122/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 16130.3671 - MAE: 99.6815\n",
      "Epoch 123/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15921.7055 - MAE: 99.2216\n",
      "Epoch 124/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 15617.7116 - MAE: 97.4927\n",
      "Epoch 125/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 16115.6988 - MAE: 98.2921\n",
      "Epoch 126/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15624.7854 - MAE: 98.2183\n",
      "Epoch 127/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15543.8747 - MAE: 97.6856\n",
      "Epoch 128/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 15613.9612 - MAE: 97.6895\n",
      "Epoch 129/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 15985.5915 - MAE: 98.4076\n",
      "Epoch 130/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 15646.6719 - MAE: 98.0876\n",
      "Epoch 131/250\n",
      "425/425 [==============================] - 0s 74us/step - loss: 15741.3990 - MAE: 98.0832\n",
      "Epoch 132/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 15529.3444 - MAE: 96.5950\n",
      "Epoch 133/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15851.4641 - MAE: 98.3848\n",
      "Epoch 134/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15477.5737 - MAE: 97.5469\n",
      "Epoch 135/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15786.5985 - MAE: 97.1836\n",
      "Epoch 136/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15452.8901 - MAE: 97.4556\n",
      "Epoch 137/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15509.5972 - MAE: 97.1775\n",
      "Epoch 138/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15567.9861 - MAE: 98.1547\n",
      "Epoch 139/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15763.9015 - MAE: 96.8619\n",
      "Epoch 140/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15324.8347 - MAE: 95.9834\n",
      "Epoch 141/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15430.4342 - MAE: 97.7789\n",
      "Epoch 142/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15388.6321 - MAE: 96.3098\n",
      "Epoch 143/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15613.3226 - MAE: 96.9932\n",
      "Epoch 144/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15351.0974 - MAE: 96.7262\n",
      "Epoch 145/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15600.3774 - MAE: 95.5623\n",
      "Epoch 146/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15366.1423 - MAE: 96.4856\n",
      "Epoch 147/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15625.7455 - MAE: 96.1783\n",
      "Epoch 148/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15456.1697 - MAE: 96.4409\n",
      "Epoch 149/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15456.5774 - MAE: 96.6364\n",
      "Epoch 150/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15204.9558 - MAE: 95.2831\n",
      "Epoch 151/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15461.0582 - MAE: 97.1126\n",
      "Epoch 152/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15360.6985 - MAE: 95.9047\n",
      "Epoch 153/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 16192.9011 - MAE: 96.9725\n",
      "Epoch 154/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15335.3237 - MAE: 96.8249\n",
      "Epoch 155/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15496.5646 - MAE: 96.1044\n",
      "Epoch 156/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 15434.0662 - MAE: 95.6920\n",
      "Epoch 157/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15298.5390 - MAE: 96.1570\n",
      "Epoch 158/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15318.3150 - MAE: 95.5583\n",
      "Epoch 159/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15381.5265 - MAE: 94.7392\n",
      "Epoch 160/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15354.3482 - MAE: 96.4679\n",
      "Epoch 161/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15405.0357 - MAE: 95.3279\n",
      "Epoch 162/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15427.5403 - MAE: 96.1669\n",
      "Epoch 163/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15122.9651 - MAE: 94.4779\n",
      "Epoch 164/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 15289.9279 - MAE: 95.3164\n",
      "Epoch 165/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15231.1416 - MAE: 94.7001\n",
      "Epoch 166/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 15238.8053 - MAE: 95.9158\n",
      "Epoch 167/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 15487.2458 - MAE: 95.9401\n",
      "Epoch 168/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15625.9699 - MAE: 95.7149\n",
      "Epoch 169/250\n",
      "425/425 [==============================] - 0s 74us/step - loss: 15263.4574 - MAE: 95.2078\n",
      "Epoch 170/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15323.2745 - MAE: 95.5407\n",
      "Epoch 171/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 15360.8105 - MAE: 96.7136\n",
      "Epoch 172/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15257.9105 - MAE: 94.6262\n",
      "Epoch 173/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15211.3297 - MAE: 94.2206\n",
      "Epoch 174/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 15265.5510 - MAE: 95.7719\n",
      "Epoch 175/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15010.3907 - MAE: 94.3937\n",
      "Epoch 176/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 15125.1339 - MAE: 95.3041\n",
      "Epoch 177/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15061.6573 - MAE: 94.6052\n",
      "Epoch 178/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15591.6045 - MAE: 96.0323\n",
      "Epoch 179/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 15620.2126 - MAE: 96.6036\n",
      "Epoch 180/250\n",
      "425/425 [==============================] - 0s 72us/step - loss: 14849.8383 - MAE: 94.5837\n",
      "Epoch 181/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15238.9882 - MAE: 95.8430\n",
      "Epoch 182/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 17110.4941 - MAE: 95.48 - 0s 70us/step - loss: 15047.3797 - MAE: 94.2064\n",
      "Epoch 183/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15181.0085 - MAE: 95.5510\n",
      "Epoch 184/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15430.6300 - MAE: 96.1985\n",
      "Epoch 185/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15181.0281 - MAE: 95.7891\n",
      "Epoch 186/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 15222.2548 - MAE: 95.1135\n",
      "Epoch 187/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 11743.8984 - MAE: 95.67 - 0s 71us/step - loss: 15261.6652 - MAE: 93.6584\n",
      "Epoch 188/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 15071.1153 - MAE: 94.8507\n",
      "Epoch 189/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 14983.8515 - MAE: 94.4203\n",
      "Epoch 190/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15367.7642 - MAE: 94.9456\n",
      "Epoch 191/250\n",
      "425/425 [==============================] - 0s 72us/step - loss: 15191.1525 - MAE: 93.8419\n",
      "Epoch 192/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15032.5313 - MAE: 93.9648\n",
      "Epoch 193/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15221.5490 - MAE: 96.2741\n",
      "Epoch 194/250\n",
      "425/425 [==============================] - 0s 74us/step - loss: 15263.1824 - MAE: 95.4201\n",
      "Epoch 195/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15276.8932 - MAE: 94.0916\n",
      "Epoch 196/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 15027.2377 - MAE: 93.3640\n",
      "Epoch 197/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 17081.0371 - MAE: 109.330 - 0s 71us/step - loss: 15143.7880 - MAE: 95.3556\n",
      "Epoch 198/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15124.1781 - MAE: 94.3013\n",
      "Epoch 199/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 15215.8780 - MAE: 94.2114\n",
      "Epoch 200/250\n",
      "425/425 [==============================] - 0s 72us/step - loss: 14972.7465 - MAE: 94.6290\n",
      "Epoch 201/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 14931.9186 - MAE: 93.9797\n",
      "Epoch 202/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 9496.2930 - MAE: 82.353 - 0s 71us/step - loss: 15085.5956 - MAE: 94.9482\n",
      "Epoch 203/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 15202.9886 - MAE: 93.4298\n",
      "Epoch 204/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 14993.8423 - MAE: 93.2327\n",
      "Epoch 205/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15244.0463 - MAE: 94.0661\n",
      "Epoch 206/250\n",
      "425/425 [==============================] - 0s 57us/step - loss: 15189.6030 - MAE: 95.4479\n",
      "Epoch 207/250\n",
      "425/425 [==============================] - 0s 87us/step - loss: 14913.9597 - MAE: 94.5757\n",
      "Epoch 208/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15313.1280 - MAE: 94.7918\n",
      "Epoch 209/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 15379.7188 - MAE: 95.3332\n",
      "Epoch 210/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 15417.3486 - MAE: 96.7280\n",
      "Epoch 211/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 15555.7861 - MAE: 95.1599\n",
      "Epoch 212/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15266.8396 - MAE: 95.5193\n",
      "Epoch 213/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15206.5452 - MAE: 95.6276\n",
      "Epoch 214/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 14981.8586 - MAE: 93.3076\n",
      "Epoch 215/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425/425 [==============================] - 0s 71us/step - loss: 15115.6859 - MAE: 93.8126\n",
      "Epoch 216/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 15077.9896 - MAE: 94.2455\n",
      "Epoch 217/250\n",
      "425/425 [==============================] - 0s 60us/step - loss: 15128.2505 - MAE: 93.0148\n",
      "Epoch 218/250\n",
      "425/425 [==============================] - 0s 58us/step - loss: 15162.3898 - MAE: 95.1471\n",
      "Epoch 219/250\n",
      "425/425 [==============================] - 0s 64us/step - loss: 15295.1868 - MAE: 95.3212\n",
      "Epoch 220/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 13601.0996 - MAE: 96.10 - 0s 63us/step - loss: 14975.8687 - MAE: 94.0149\n",
      "Epoch 221/250\n",
      "425/425 [==============================] - ETA: 0s - loss: 14589.9629 - MAE: 98.01 - 0s 69us/step - loss: 15074.1679 - MAE: 94.3507\n",
      "Epoch 222/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 14993.0583 - MAE: 93.8254\n",
      "Epoch 223/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 14872.9246 - MAE: 93.5956\n",
      "Epoch 224/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15050.8304 - MAE: 94.1830\n",
      "Epoch 225/250\n",
      "425/425 [==============================] - 0s 69us/step - loss: 15041.6348 - MAE: 94.5711\n",
      "Epoch 226/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 14980.9510 - MAE: 93.6799\n",
      "Epoch 227/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 14955.2249 - MAE: 92.9351\n",
      "Epoch 228/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 14902.4343 - MAE: 94.1860\n",
      "Epoch 229/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 14944.7828 - MAE: 93.5837\n",
      "Epoch 230/250\n",
      "425/425 [==============================] - 0s 67us/step - loss: 14940.4259 - MAE: 92.7607\n",
      "Epoch 231/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 14838.0713 - MAE: 93.2486\n",
      "Epoch 232/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 15444.2479 - MAE: 94.8180\n",
      "Epoch 233/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 14925.0239 - MAE: 93.3847\n",
      "Epoch 234/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 14850.0296 - MAE: 92.6676\n",
      "Epoch 235/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 15035.1692 - MAE: 94.5709\n",
      "Epoch 236/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 14877.9570 - MAE: 92.6173\n",
      "Epoch 237/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 14790.5590 - MAE: 92.6754\n",
      "Epoch 238/250\n",
      "425/425 [==============================] - 0s 66us/step - loss: 14938.2465 - MAE: 92.8667\n",
      "Epoch 239/250\n",
      "425/425 [==============================] - 0s 65us/step - loss: 14742.8600 - MAE: 91.5343\n",
      "Epoch 240/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 15963.5064 - MAE: 97.3926\n",
      "Epoch 241/250\n",
      "425/425 [==============================] - 0s 71us/step - loss: 14761.1339 - MAE: 93.5744\n",
      "Epoch 242/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 14807.5792 - MAE: 93.2652\n",
      "Epoch 243/250\n",
      "425/425 [==============================] - 0s 67us/step - loss: 14878.1062 - MAE: 92.6456\n",
      "Epoch 244/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 15134.9034 - MAE: 93.7043\n",
      "Epoch 245/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 14839.3757 - MAE: 92.2292\n",
      "Epoch 246/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 14872.5454 - MAE: 93.2183\n",
      "Epoch 247/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 14736.5348 - MAE: 91.3897\n",
      "Epoch 248/250\n",
      "425/425 [==============================] - 0s 70us/step - loss: 14989.2416 - MAE: 94.5575\n",
      "Epoch 249/250\n",
      "425/425 [==============================] - 0s 73us/step - loss: 14822.9936 - MAE: 93.4692\n",
      "Epoch 250/250\n",
      "425/425 [==============================] - 0s 68us/step - loss: 14774.4026 - MAE: 93.3910\n",
      "425/425 [==============================] - 0s 33us/step\n",
      "\n",
      " 2 fold accuracy: ['92.1752', '101.5428']\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "df = pd.read_excel('./res/데이터/movie_score.xlsx')\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:, 2:8]\n",
    "Y_obj = dataset[:, 1]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "\n",
    "# 2개의 파일로 쪼갬\n",
    "n_fold = 2\n",
    "skf = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = seed)\n",
    "\n",
    "# 빈 accuracy 배열\n",
    "accuracy = []\n",
    "\n",
    "for train, test in skf.split(X, Y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=6, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['MAE'])\n",
    "\n",
    "    model.fit(X[train], Y[train], epochs=250, batch_size=10)\n",
    "    \n",
    "    k_accuracy = '%.4f' % (model.evaluate(X[test], Y[test])[1])\n",
    "    accuracy.append(k_accuracy)\n",
    "    \n",
    "# 결과 출력\n",
    "print('\\n %.f fold accuracy:' % n_fold, accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 리얼 최종"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 637 samples, validate on 213 samples\n",
      "Epoch 1/1000\n",
      "637/637 [==============================] - 0s 187us/step - loss: 0.7905 - MAE: 128.1604 - val_loss: 0.7064 - val_MAE: 116.0515\n",
      "Epoch 2/1000\n",
      "637/637 [==============================] - 0s 55us/step - loss: 0.5116 - MAE: 109.7048 - val_loss: 0.8367 - val_MAE: 123.4148\n",
      "Epoch 3/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.4757 - MAE: 106.3317 - val_loss: 0.7689 - val_MAE: 118.6393\n",
      "Epoch 4/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.4337 - MAE: 102.7712 - val_loss: 0.8511 - val_MAE: 123.6724\n",
      "Epoch 5/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.4059 - MAE: 98.4277 - val_loss: 0.9759 - val_MAE: 132.6316\n",
      "Epoch 6/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.3970 - MAE: 96.8471 - val_loss: 0.8460 - val_MAE: 122.0895\n",
      "Epoch 7/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.3856 - MAE: 95.8996 - val_loss: 0.9281 - val_MAE: 128.5492\n",
      "Epoch 8/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.3802 - MAE: 95.1891 - val_loss: 0.9504 - val_MAE: 130.4711\n",
      "Epoch 9/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.3749 - MAE: 94.5891 - val_loss: 0.8445 - val_MAE: 121.9343\n",
      "Epoch 10/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.3691 - MAE: 94.7986 - val_loss: 0.9392 - val_MAE: 129.4485\n",
      "Epoch 11/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.3680 - MAE: 93.6958 - val_loss: 0.9276 - val_MAE: 128.6390\n",
      "Epoch 12/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.3607 - MAE: 93.2648 - val_loss: 0.8516 - val_MAE: 122.6264\n",
      "Epoch 13/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.3584 - MAE: 93.0047 - val_loss: 0.8183 - val_MAE: 120.2319\n",
      "Epoch 14/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.3541 - MAE: 92.5215 - val_loss: 0.7935 - val_MAE: 118.4689\n",
      "Epoch 15/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.3495 - MAE: 92.1013 - val_loss: 0.8333 - val_MAE: 121.5174\n",
      "Epoch 16/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.3459 - MAE: 92.2388 - val_loss: 0.8677 - val_MAE: 124.2448\n",
      "Epoch 17/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.3403 - MAE: 90.9594 - val_loss: 0.7678 - val_MAE: 116.6600\n",
      "Epoch 18/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.3401 - MAE: 90.5657 - val_loss: 0.7130 - val_MAE: 112.6909\n",
      "Epoch 19/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.3386 - MAE: 91.2428 - val_loss: 0.8520 - val_MAE: 123.2873\n",
      "Epoch 20/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.3318 - MAE: 90.3475 - val_loss: 0.9199 - val_MAE: 128.5820\n",
      "Epoch 21/1000\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.2160 - MAE: 59.62 - 0s 41us/step - loss: 0.3254 - MAE: 89.2979 - val_loss: 0.7856 - val_MAE: 118.1582\n",
      "Epoch 22/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.3247 - MAE: 89.2314 - val_loss: 0.7472 - val_MAE: 115.1487\n",
      "Epoch 23/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.3195 - MAE: 89.1293 - val_loss: 0.8271 - val_MAE: 121.4245\n",
      "Epoch 24/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.3156 - MAE: 88.4823 - val_loss: 0.9085 - val_MAE: 128.2610\n",
      "Epoch 25/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.3104 - MAE: 88.1903 - val_loss: 0.8565 - val_MAE: 123.9254\n",
      "Epoch 26/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.3064 - MAE: 87.6699 - val_loss: 0.8381 - val_MAE: 122.5676\n",
      "Epoch 27/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.3066 - MAE: 87.3965 - val_loss: 0.8949 - val_MAE: 127.8656\n",
      "Epoch 28/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2996 - MAE: 86.8726 - val_loss: 0.8372 - val_MAE: 122.9360\n",
      "Epoch 29/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2951 - MAE: 86.4108 - val_loss: 0.8094 - val_MAE: 120.7228\n",
      "Epoch 30/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2928 - MAE: 85.6752 - val_loss: 0.7791 - val_MAE: 118.3552\n",
      "Epoch 31/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2913 - MAE: 85.7827 - val_loss: 0.7519 - val_MAE: 116.1533\n",
      "Epoch 32/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2853 - MAE: 85.0659 - val_loss: 0.8541 - val_MAE: 125.4720\n",
      "Epoch 33/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2846 - MAE: 85.2100 - val_loss: 0.8202 - val_MAE: 122.5395\n",
      "Epoch 34/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2825 - MAE: 83.7974 - val_loss: 0.7715 - val_MAE: 118.3186\n",
      "Epoch 35/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2778 - MAE: 84.4267 - val_loss: 0.7875 - val_MAE: 120.0759\n",
      "Epoch 36/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2835 - MAE: 83.9051 - val_loss: 0.7608 - val_MAE: 117.8615\n",
      "Epoch 37/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2759 - MAE: 83.9565 - val_loss: 0.7884 - val_MAE: 120.5648\n",
      "Epoch 38/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2724 - MAE: 83.3498 - val_loss: 0.8068 - val_MAE: 123.0217\n",
      "Epoch 39/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2710 - MAE: 82.6285 - val_loss: 0.8608 - val_MAE: 128.9684\n",
      "Epoch 40/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2645 - MAE: 82.2977 - val_loss: 0.7660 - val_MAE: 119.2753\n",
      "Epoch 41/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2626 - MAE: 80.5355 - val_loss: 0.5438 - val_MAE: 99.1526\n",
      "Epoch 42/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2782 - MAE: 84.5376 - val_loss: 0.6520 - val_MAE: 108.5016\n",
      "Epoch 43/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2633 - MAE: 82.1430 - val_loss: 0.7820 - val_MAE: 121.8847\n",
      "Epoch 44/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2631 - MAE: 81.4498 - val_loss: 0.8000 - val_MAE: 124.0288\n",
      "Epoch 45/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2613 - MAE: 81.8985 - val_loss: 0.8156 - val_MAE: 126.4375\n",
      "Epoch 46/1000\n",
      "637/637 [==============================] - 0s 40us/step - loss: 0.2589 - MAE: 80.7834 - val_loss: 0.7927 - val_MAE: 123.6352\n",
      "Epoch 47/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2590 - MAE: 81.4566 - val_loss: 0.7648 - val_MAE: 121.2984\n",
      "Epoch 48/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2563 - MAE: 80.5978 - val_loss: 0.6878 - val_MAE: 112.8775\n",
      "Epoch 49/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2575 - MAE: 81.0881 - val_loss: 0.7142 - val_MAE: 115.9884\n",
      "Epoch 50/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2523 - MAE: 79.8982 - val_loss: 0.6367 - val_MAE: 107.6700\n",
      "Epoch 51/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2537 - MAE: 80.5035 - val_loss: 0.7231 - val_MAE: 117.4447\n",
      "Epoch 52/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2536 - MAE: 80.3440 - val_loss: 0.7466 - val_MAE: 120.2575\n",
      "Epoch 53/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2517 - MAE: 80.5412 - val_loss: 0.7803 - val_MAE: 124.2469\n",
      "Epoch 54/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2500 - MAE: 81.0834 - val_loss: 0.8342 - val_MAE: 131.2084\n",
      "Epoch 55/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2513 - MAE: 79.9457 - val_loss: 0.7432 - val_MAE: 120.6236\n",
      "Epoch 56/1000\n",
      "637/637 [==============================] - 0s 40us/step - loss: 0.2505 - MAE: 79.3987 - val_loss: 0.7499 - val_MAE: 121.1323\n",
      "Epoch 57/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2525 - MAE: 79.4694 - val_loss: 0.5692 - val_MAE: 101.1544\n",
      "Epoch 58/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2511 - MAE: 80.3797 - val_loss: 0.6927 - val_MAE: 115.0132\n",
      "Epoch 59/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2457 - MAE: 79.0391 - val_loss: 0.7017 - val_MAE: 116.7150\n",
      "Epoch 60/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2463 - MAE: 79.0663 - val_loss: 0.6148 - val_MAE: 106.0520\n",
      "Epoch 61/1000\n",
      "637/637 [==============================] - 0s 40us/step - loss: 0.2472 - MAE: 79.7020 - val_loss: 0.7160 - val_MAE: 118.1373\n",
      "Epoch 62/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2493 - MAE: 78.8702 - val_loss: 0.6924 - val_MAE: 115.8137\n",
      "Epoch 63/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2458 - MAE: 79.1448 - val_loss: 0.6115 - val_MAE: 105.8528\n",
      "Epoch 64/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2434 - MAE: 79.0127 - val_loss: 0.6005 - val_MAE: 104.8353\n",
      "Epoch 65/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2445 - MAE: 78.3850 - val_loss: 0.6777 - val_MAE: 114.7154\n",
      "Epoch 66/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2432 - MAE: 78.8215 - val_loss: 0.7150 - val_MAE: 119.1676\n",
      "Epoch 67/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2425 - MAE: 78.6055 - val_loss: 0.6913 - val_MAE: 116.4450\n",
      "Epoch 68/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2442 - MAE: 78.7645 - val_loss: 0.6733 - val_MAE: 114.3431\n",
      "Epoch 69/1000\n",
      "637/637 [==============================] - 0s 43us/step - loss: 0.2404 - MAE: 78.2409 - val_loss: 0.6834 - val_MAE: 116.0915\n",
      "Epoch 70/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2411 - MAE: 78.3791 - val_loss: 0.6990 - val_MAE: 118.5429\n",
      "Epoch 71/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2418 - MAE: 78.1550 - val_loss: 0.7141 - val_MAE: 119.9012\n",
      "Epoch 72/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2426 - MAE: 78.4595 - val_loss: 0.6298 - val_MAE: 109.4505\n",
      "Epoch 73/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2383 - MAE: 78.3394 - val_loss: 0.7264 - val_MAE: 121.6243\n",
      "Epoch 74/1000\n",
      "637/637 [==============================] - 0s 43us/step - loss: 0.2401 - MAE: 77.7592 - val_loss: 0.7527 - val_MAE: 125.0960\n",
      "Epoch 75/1000\n",
      "637/637 [==============================] - 0s 43us/step - loss: 0.2400 - MAE: 77.5986 - val_loss: 0.6434 - val_MAE: 111.8350\n",
      "Epoch 76/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2411 - MAE: 77.9746 - val_loss: 0.6449 - val_MAE: 112.0273\n",
      "Epoch 77/1000\n",
      "637/637 [==============================] - 0s 40us/step - loss: 0.2391 - MAE: 77.8989 - val_loss: 0.7500 - val_MAE: 124.8461\n",
      "Epoch 78/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2413 - MAE: 78.1647 - val_loss: 0.6627 - val_MAE: 114.4320\n",
      "Epoch 79/1000\n",
      "637/637 [==============================] - 0s 43us/step - loss: 0.2382 - MAE: 77.5901 - val_loss: 0.7060 - val_MAE: 119.7018\n",
      "Epoch 80/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2393 - MAE: 78.0035 - val_loss: 0.5965 - val_MAE: 105.9645\n",
      "Epoch 81/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2379 - MAE: 77.5873 - val_loss: 0.7511 - val_MAE: 125.5735\n",
      "Epoch 82/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2452 - MAE: 78.3084 - val_loss: 0.7194 - val_MAE: 122.0118\n",
      "Epoch 83/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2398 - MAE: 77.4213 - val_loss: 0.7124 - val_MAE: 120.3562\n",
      "Epoch 84/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2403 - MAE: 78.2728 - val_loss: 0.5854 - val_MAE: 104.5194\n",
      "Epoch 85/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2364 - MAE: 77.5233 - val_loss: 0.7281 - val_MAE: 122.5884\n",
      "Epoch 86/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2363 - MAE: 77.2520 - val_loss: 0.7347 - val_MAE: 123.6938\n",
      "Epoch 87/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2366 - MAE: 77.7318 - val_loss: 0.6301 - val_MAE: 110.2502\n",
      "Epoch 88/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2360 - MAE: 77.1685 - val_loss: 0.6333 - val_MAE: 110.6581\n",
      "Epoch 89/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2393 - MAE: 77.6566 - val_loss: 0.6465 - val_MAE: 111.4198\n",
      "Epoch 90/1000\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.1827 - MAE: 70.35 - 0s 42us/step - loss: 0.2367 - MAE: 77.7135 - val_loss: 0.6571 - val_MAE: 114.1157\n",
      "Epoch 91/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2362 - MAE: 77.2739 - val_loss: 0.5634 - val_MAE: 101.6081\n",
      "Epoch 92/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2370 - MAE: 77.4474 - val_loss: 0.7041 - val_MAE: 119.6023\n",
      "Epoch 93/1000\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.2019 - MAE: 105.856 - 0s 40us/step - loss: 0.2392 - MAE: 77.8844 - val_loss: 0.6186 - val_MAE: 109.0914\n",
      "Epoch 94/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2363 - MAE: 77.0808 - val_loss: 0.6269 - val_MAE: 109.9360\n",
      "Epoch 95/1000\n",
      "637/637 [==============================] - 0s 43us/step - loss: 0.2338 - MAE: 76.8906 - val_loss: 0.6791 - val_MAE: 116.9320\n",
      "Epoch 96/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2343 - MAE: 76.7382 - val_loss: 0.6150 - val_MAE: 108.0515\n",
      "Epoch 97/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2355 - MAE: 77.3465 - val_loss: 0.6904 - val_MAE: 118.4749\n",
      "Epoch 98/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2329 - MAE: 76.7771 - val_loss: 0.6316 - val_MAE: 110.2355\n",
      "Epoch 99/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2355 - MAE: 77.3105 - val_loss: 0.7114 - val_MAE: 121.1568\n",
      "Epoch 100/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2367 - MAE: 77.7311 - val_loss: 0.6868 - val_MAE: 118.0245\n",
      "Epoch 101/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2389 - MAE: 77.0766 - val_loss: 0.5999 - val_MAE: 106.5268\n",
      "Epoch 102/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2379 - MAE: 76.7900 - val_loss: 0.5645 - val_MAE: 101.7483\n",
      "Epoch 103/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2353 - MAE: 77.3439 - val_loss: 0.5952 - val_MAE: 105.7417\n",
      "Epoch 104/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2327 - MAE: 76.5355 - val_loss: 0.5857 - val_MAE: 104.3216\n",
      "Epoch 105/1000\n",
      "637/637 [==============================] - ETA: 0s - loss: 0.2209 - MAE: 53.60 - 0s 44us/step - loss: 0.2373 - MAE: 77.4461 - val_loss: 0.7597 - val_MAE: 125.6453\n",
      "Epoch 106/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2347 - MAE: 77.2754 - val_loss: 0.6433 - val_MAE: 111.3983\n",
      "Epoch 107/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2353 - MAE: 77.9302 - val_loss: 0.6513 - val_MAE: 112.8099\n",
      "Epoch 108/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2346 - MAE: 77.2569 - val_loss: 0.6412 - val_MAE: 110.8638\n",
      "Epoch 109/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2352 - MAE: 77.2761 - val_loss: 0.6033 - val_MAE: 106.5334\n",
      "Epoch 110/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2319 - MAE: 76.2718 - val_loss: 0.5975 - val_MAE: 105.7446\n",
      "Epoch 111/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2340 - MAE: 77.5758 - val_loss: 0.5745 - val_MAE: 102.7866\n",
      "Epoch 112/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2313 - MAE: 77.3574 - val_loss: 0.5459 - val_MAE: 99.0839\n",
      "Epoch 113/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2351 - MAE: 77.4530 - val_loss: 0.6448 - val_MAE: 111.7088\n",
      "Epoch 114/1000\n",
      "637/637 [==============================] - 0s 40us/step - loss: 0.2307 - MAE: 76.3844 - val_loss: 0.5926 - val_MAE: 104.9242\n",
      "Epoch 115/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2328 - MAE: 76.7212 - val_loss: 0.5562 - val_MAE: 99.9768\n",
      "Epoch 116/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2342 - MAE: 76.1989 - val_loss: 0.5880 - val_MAE: 103.5818\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637/637 [==============================] - 0s 42us/step - loss: 0.2323 - MAE: 76.7783 - val_loss: 0.6689 - val_MAE: 115.0109\n",
      "Epoch 118/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2302 - MAE: 76.3174 - val_loss: 0.6543 - val_MAE: 113.3348\n",
      "Epoch 119/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2286 - MAE: 75.6939 - val_loss: 0.6102 - val_MAE: 106.7346\n",
      "Epoch 120/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2289 - MAE: 76.5121 - val_loss: 0.6737 - val_MAE: 115.3554\n",
      "Epoch 121/1000\n",
      "637/637 [==============================] - 0s 40us/step - loss: 0.2286 - MAE: 76.1299 - val_loss: 0.6943 - val_MAE: 118.4244\n",
      "Epoch 122/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2298 - MAE: 76.1084 - val_loss: 0.6786 - val_MAE: 115.7946\n",
      "Epoch 123/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2287 - MAE: 76.3836 - val_loss: 0.7618 - val_MAE: 128.4079\n",
      "Epoch 124/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2264 - MAE: 75.5777 - val_loss: 0.6715 - val_MAE: 113.8403\n",
      "Epoch 125/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2308 - MAE: 75.8476 - val_loss: 0.6569 - val_MAE: 112.7334\n",
      "Epoch 126/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2272 - MAE: 76.0330 - val_loss: 0.6625 - val_MAE: 114.3499\n",
      "Epoch 127/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2293 - MAE: 75.2725 - val_loss: 0.5788 - val_MAE: 102.8484\n",
      "Epoch 128/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2262 - MAE: 75.8876 - val_loss: 0.5593 - val_MAE: 99.9714\n",
      "Epoch 129/1000\n",
      "637/637 [==============================] - 0s 43us/step - loss: 0.2290 - MAE: 76.4079 - val_loss: 0.6172 - val_MAE: 108.0886\n",
      "Epoch 130/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2261 - MAE: 75.4377 - val_loss: 0.7054 - val_MAE: 120.9593\n",
      "Epoch 131/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2248 - MAE: 75.8444 - val_loss: 0.5775 - val_MAE: 102.7269\n",
      "Epoch 132/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2264 - MAE: 75.9779 - val_loss: 0.6072 - val_MAE: 107.3435\n",
      "Epoch 133/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2253 - MAE: 75.7661 - val_loss: 0.6506 - val_MAE: 113.1611\n",
      "Epoch 134/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2251 - MAE: 75.7060 - val_loss: 0.6360 - val_MAE: 110.4074\n",
      "Epoch 135/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2249 - MAE: 75.3121 - val_loss: 0.6041 - val_MAE: 106.4926\n",
      "Epoch 136/1000\n",
      "637/637 [==============================] - 0s 43us/step - loss: 0.2231 - MAE: 75.2677 - val_loss: 0.6339 - val_MAE: 110.9487\n",
      "Epoch 137/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2245 - MAE: 75.5844 - val_loss: 0.6973 - val_MAE: 118.9440\n",
      "Epoch 138/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2229 - MAE: 75.3030 - val_loss: 0.6005 - val_MAE: 106.4029\n",
      "Epoch 139/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2228 - MAE: 75.0012 - val_loss: 0.6709 - val_MAE: 115.9429\n",
      "Epoch 140/1000\n",
      "637/637 [==============================] - 0s 39us/step - loss: 0.2212 - MAE: 75.0003 - val_loss: 0.5583 - val_MAE: 99.7477\n",
      "Epoch 141/1000\n",
      "637/637 [==============================] - 0s 40us/step - loss: 0.2242 - MAE: 75.5409 - val_loss: 0.6784 - val_MAE: 116.5983\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-557f4dc1ab08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mY_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "df = pd.read_excel('./res/데이터/movie_score.xlsx')\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:, 2:8]\n",
    "Y = dataset[:, 1]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=6, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['MAE'])\n",
    "\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)\n",
    "model.fit(X,Y, validation_split=0.25, epochs=1000, batch_size=20, callbacks=[early_stopping_callback])\n",
    "\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    label = Y_test[i].astype(float)\n",
    "    prediction = Y_prediction[i].astype(float)\n",
    "    print(\"실제관객:%.3f, 예상관객 :%.3f\"%(label, prediction))\n",
    "    \n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 진짜최종"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Bigdata\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 637 samples, validate on 213 samples\n",
      "Epoch 1/1000\n",
      "637/637 [==============================] - 0s 219us/step - loss: 1.3447 - MAE: 264.1644 - val_loss: 0.7405 - val_MAE: 128.7435\n",
      "Epoch 2/1000\n",
      "637/637 [==============================] - 0s 55us/step - loss: 0.5766 - MAE: 168.6206 - val_loss: 0.8633 - val_MAE: 134.6568\n",
      "Epoch 3/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.5606 - MAE: 154.5264 - val_loss: 0.8790 - val_MAE: 137.1859\n",
      "Epoch 4/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.5543 - MAE: 149.8379 - val_loss: 0.8833 - val_MAE: 138.0066\n",
      "Epoch 5/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.5422 - MAE: 149.7538 - val_loss: 0.8809 - val_MAE: 137.8592\n",
      "Epoch 6/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.5275 - MAE: 150.5725 - val_loss: 0.8857 - val_MAE: 139.2988\n",
      "Epoch 7/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.5119 - MAE: 144.7841 - val_loss: 0.8898 - val_MAE: 141.5129\n",
      "Epoch 8/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.4987 - MAE: 144.7883 - val_loss: 0.8906 - val_MAE: 144.2822\n",
      "Epoch 9/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.4880 - MAE: 142.3051 - val_loss: 0.8813 - val_MAE: 144.8299\n",
      "Epoch 10/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.4681 - MAE: 136.2597 - val_loss: 0.9413 - val_MAE: 163.2077\n",
      "Epoch 11/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.4572 - MAE: 134.6888 - val_loss: 0.9302 - val_MAE: 163.2075\n",
      "Epoch 12/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.4472 - MAE: 130.2289 - val_loss: 0.9356 - val_MAE: 167.9876\n",
      "Epoch 13/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.4384 - MAE: 132.3678 - val_loss: 0.9653 - val_MAE: 179.6051\n",
      "Epoch 14/1000\n",
      "637/637 [==============================] - 0s 43us/step - loss: 0.4481 - MAE: 127.5786 - val_loss: 1.0035 - val_MAE: 193.6612\n",
      "Epoch 15/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.4295 - MAE: 121.8183 - val_loss: 0.8371 - val_MAE: 142.8575\n",
      "Epoch 16/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.4242 - MAE: 129.0081 - val_loss: 0.9324 - val_MAE: 173.9606\n",
      "Epoch 17/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.4124 - MAE: 122.7289 - val_loss: 0.8139 - val_MAE: 142.6255\n",
      "Epoch 18/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.4080 - MAE: 123.4608 - val_loss: 0.9003 - val_MAE: 170.5643\n",
      "Epoch 19/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.4034 - MAE: 121.5244 - val_loss: 0.9491 - val_MAE: 187.7836\n",
      "Epoch 20/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.3982 - MAE: 118.5319 - val_loss: 0.8236 - val_MAE: 151.3730\n",
      "Epoch 21/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.3924 - MAE: 115.9377 - val_loss: 0.8333 - val_MAE: 156.4676\n",
      "Epoch 22/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.3875 - MAE: 117.5958 - val_loss: 0.8248 - val_MAE: 154.9252\n",
      "Epoch 23/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.3826 - MAE: 113.5988 - val_loss: 0.7750 - val_MAE: 142.7083\n",
      "Epoch 24/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.3812 - MAE: 114.5023 - val_loss: 0.7377 - val_MAE: 131.7446\n",
      "Epoch 25/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.3847 - MAE: 113.2428 - val_loss: 0.6903 - val_MAE: 118.2037\n",
      "Epoch 26/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.3828 - MAE: 114.0326 - val_loss: 0.7518 - val_MAE: 137.3423\n",
      "Epoch 27/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.3655 - MAE: 111.1466 - val_loss: 0.8843 - val_MAE: 182.8007\n",
      "Epoch 28/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.3677 - MAE: 110.6464 - val_loss: 0.8294 - val_MAE: 165.3205\n",
      "Epoch 29/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.3622 - MAE: 107.6781 - val_loss: 0.7043 - val_MAE: 123.6830\n",
      "Epoch 30/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.3615 - MAE: 109.0018 - val_loss: 0.6610 - val_MAE: 114.7987\n",
      "Epoch 31/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.3616 - MAE: 108.2439 - val_loss: 0.7110 - val_MAE: 127.9489\n",
      "Epoch 32/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.3565 - MAE: 104.3534 - val_loss: 0.6817 - val_MAE: 120.1022\n",
      "Epoch 33/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.3580 - MAE: 106.6621 - val_loss: 0.6775 - val_MAE: 118.3435\n",
      "Epoch 34/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.3513 - MAE: 107.0821 - val_loss: 0.7830 - val_MAE: 150.9756\n",
      "Epoch 35/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.3445 - MAE: 103.5793 - val_loss: 0.7524 - val_MAE: 142.7332\n",
      "Epoch 36/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.3414 - MAE: 103.2165 - val_loss: 0.8031 - val_MAE: 163.8655\n",
      "Epoch 37/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3417 - MAE: 102.0556 - val_loss: 0.7889 - val_MAE: 157.6190\n",
      "Epoch 38/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.3432 - MAE: 101.1650 - val_loss: 0.7907 - val_MAE: 157.4669\n",
      "Epoch 39/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.3359 - MAE: 102.2274 - val_loss: 0.6855 - val_MAE: 122.1237\n",
      "Epoch 40/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3352 - MAE: 102.8680 - val_loss: 0.6859 - val_MAE: 125.4567\n",
      "Epoch 41/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.3302 - MAE: 98.9212 - val_loss: 0.6414 - val_MAE: 113.1144\n",
      "Epoch 42/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3246 - MAE: 96.9700 - val_loss: 0.6942 - val_MAE: 127.7422\n",
      "Epoch 43/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3197 - MAE: 95.9207 - val_loss: 0.6750 - val_MAE: 123.7985\n",
      "Epoch 44/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.3217 - MAE: 95.5151 - val_loss: 0.6178 - val_MAE: 108.9791\n",
      "Epoch 45/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3243 - MAE: 99.3385 - val_loss: 0.6750 - val_MAE: 124.5685\n",
      "Epoch 46/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3168 - MAE: 96.1881 - val_loss: 0.6504 - val_MAE: 116.2157\n",
      "Epoch 47/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3129 - MAE: 93.7000 - val_loss: 0.6784 - val_MAE: 126.0762\n",
      "Epoch 48/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3131 - MAE: 93.5844 - val_loss: 0.7260 - val_MAE: 143.7933\n",
      "Epoch 49/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.3119 - MAE: 97.7765 - val_loss: 0.8549 - val_MAE: 193.3232\n",
      "Epoch 50/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3242 - MAE: 99.0909 - val_loss: 0.7757 - val_MAE: 163.7872\n",
      "Epoch 51/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.3117 - MAE: 97.7366 - val_loss: 0.6519 - val_MAE: 117.1882\n",
      "Epoch 52/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3084 - MAE: 91.7829 - val_loss: 0.6010 - val_MAE: 108.2300\n",
      "Epoch 53/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.3109 - MAE: 97.8280 - val_loss: 0.5549 - val_MAE: 105.6959\n",
      "Epoch 54/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.3012 - MAE: 93.1860 - val_loss: 0.5851 - val_MAE: 108.9933\n",
      "Epoch 55/1000\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.3055 - MAE: 93.0545 - val_loss: 0.5934 - val_MAE: 106.9098\n",
      "Epoch 56/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2966 - MAE: 92.6116 - val_loss: 0.6539 - val_MAE: 118.4388\n",
      "Epoch 57/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.3180 - MAE: 95.3306 - val_loss: 0.5853 - val_MAE: 104.7511\n",
      "Epoch 58/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.3065 - MAE: 96.5347 - val_loss: 0.5575 - val_MAE: 110.6206\n",
      "Epoch 59/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2980 - MAE: 92.4187 - val_loss: 0.5809 - val_MAE: 106.8436\n",
      "Epoch 60/1000\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.2923 - MAE: 86.8470 - val_loss: 0.6071 - val_MAE: 110.2672\n",
      "Epoch 61/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2914 - MAE: 88.8598 - val_loss: 0.5367 - val_MAE: 108.2970\n",
      "Epoch 62/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2919 - MAE: 92.2883 - val_loss: 0.5673 - val_MAE: 107.4302\n",
      "Epoch 63/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2896 - MAE: 90.6999 - val_loss: 0.6736 - val_MAE: 130.7628\n",
      "Epoch 64/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2863 - MAE: 85.7952 - val_loss: 0.6787 - val_MAE: 134.0772\n",
      "Epoch 65/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2820 - MAE: 87.9323 - val_loss: 0.6441 - val_MAE: 118.9068\n",
      "Epoch 66/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2802 - MAE: 86.6668 - val_loss: 0.6471 - val_MAE: 121.0209\n",
      "Epoch 67/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2815 - MAE: 85.4510 - val_loss: 0.6158 - val_MAE: 110.4844\n",
      "Epoch 68/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2768 - MAE: 86.2133 - val_loss: 0.5962 - val_MAE: 108.1988\n",
      "Epoch 69/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2806 - MAE: 88.8796 - val_loss: 0.5631 - val_MAE: 106.1680\n",
      "Epoch 70/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2773 - MAE: 84.4445 - val_loss: 0.6244 - val_MAE: 113.4865\n",
      "Epoch 71/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2739 - MAE: 86.8628 - val_loss: 0.5713 - val_MAE: 101.4404\n",
      "Epoch 72/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2839 - MAE: 89.3090 - val_loss: 0.6695 - val_MAE: 128.2014\n",
      "Epoch 73/1000\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.2771 - MAE: 85.8395 - val_loss: 0.7132 - val_MAE: 144.5911\n",
      "Epoch 74/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2813 - MAE: 85.0244 - val_loss: 0.6268 - val_MAE: 112.3021\n",
      "Epoch 75/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2717 - MAE: 85.9989 - val_loss: 0.6039 - val_MAE: 108.3861\n",
      "Epoch 76/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2675 - MAE: 83.3003 - val_loss: 0.5882 - val_MAE: 110.2576\n",
      "Epoch 77/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2811 - MAE: 89.3598 - val_loss: 0.6286 - val_MAE: 113.5292\n",
      "Epoch 78/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2692 - MAE: 83.4337 - val_loss: 0.6007 - val_MAE: 109.3297\n",
      "Epoch 79/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2698 - MAE: 84.2526 - val_loss: 0.5946 - val_MAE: 107.4006\n",
      "Epoch 80/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2697 - MAE: 86.9948 - val_loss: 0.6037 - val_MAE: 108.1140\n",
      "Epoch 81/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2716 - MAE: 84.6420 - val_loss: 0.5745 - val_MAE: 99.3780\n",
      "Epoch 82/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2589 - MAE: 83.4571 - val_loss: 0.5839 - val_MAE: 110.1944\n",
      "Epoch 83/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2630 - MAE: 84.2924 - val_loss: 0.5896 - val_MAE: 106.9994\n",
      "Epoch 84/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2624 - MAE: 81.6023 - val_loss: 0.5966 - val_MAE: 108.7571\n",
      "Epoch 85/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2611 - MAE: 81.9403 - val_loss: 0.6168 - val_MAE: 115.1917\n",
      "Epoch 86/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2591 - MAE: 83.2284 - val_loss: 0.6145 - val_MAE: 113.0759\n",
      "Epoch 87/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2601 - MAE: 83.2718 - val_loss: 0.5738 - val_MAE: 101.2397\n",
      "Epoch 88/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2646 - MAE: 84.6739 - val_loss: 0.5817 - val_MAE: 104.8487\n",
      "Epoch 89/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2675 - MAE: 78.2252 - val_loss: 0.6637 - val_MAE: 122.4428\n",
      "Epoch 90/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2602 - MAE: 88.2298 - val_loss: 0.6065 - val_MAE: 110.7998\n",
      "Epoch 91/1000\n",
      "637/637 [==============================] - 0s 43us/step - loss: 0.2604 - MAE: 80.5254 - val_loss: 0.6049 - val_MAE: 110.9753\n",
      "Epoch 92/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2529 - MAE: 78.6890 - val_loss: 0.5391 - val_MAE: 102.8703\n",
      "Epoch 93/1000\n",
      "637/637 [==============================] - 0s 40us/step - loss: 0.2541 - MAE: 80.6601 - val_loss: 0.5427 - val_MAE: 104.3845\n",
      "Epoch 94/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2588 - MAE: 83.4891 - val_loss: 0.5949 - val_MAE: 108.4514\n",
      "Epoch 95/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2542 - MAE: 81.9029 - val_loss: 0.6605 - val_MAE: 135.2493\n",
      "Epoch 96/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2639 - MAE: 80.4082 - val_loss: 0.5620 - val_MAE: 105.4562\n",
      "Epoch 97/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2494 - MAE: 80.6014 - val_loss: 0.6034 - val_MAE: 110.4593\n",
      "Epoch 98/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2529 - MAE: 81.0400 - val_loss: 0.6459 - val_MAE: 127.8372\n",
      "Epoch 99/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2501 - MAE: 80.2461 - val_loss: 0.5866 - val_MAE: 104.8494\n",
      "Epoch 100/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2461 - MAE: 77.8390 - val_loss: 0.5548 - val_MAE: 106.8251\n",
      "Epoch 101/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2542 - MAE: 82.0060 - val_loss: 0.6376 - val_MAE: 127.6353\n",
      "Epoch 102/1000\n",
      "637/637 [==============================] - 0s 48us/step - loss: 0.2459 - MAE: 79.4437 - val_loss: 0.5618 - val_MAE: 99.7491\n",
      "Epoch 103/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2476 - MAE: 82.5046 - val_loss: 0.7350 - val_MAE: 166.1359\n",
      "Epoch 104/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2698 - MAE: 84.8549 - val_loss: 0.5884 - val_MAE: 106.6030\n",
      "Epoch 105/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2536 - MAE: 82.3786 - val_loss: 0.5808 - val_MAE: 107.0014\n",
      "Epoch 106/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2574 - MAE: 82.2869 - val_loss: 0.5473 - val_MAE: 96.0240\n",
      "Epoch 107/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2501 - MAE: 77.1634 - val_loss: 0.5316 - val_MAE: 101.5359\n",
      "Epoch 108/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2606 - MAE: 85.1230 - val_loss: 0.6063 - val_MAE: 111.0674\n",
      "Epoch 109/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2620 - MAE: 83.9324 - val_loss: 0.5714 - val_MAE: 102.5553\n",
      "Epoch 110/1000\n",
      "637/637 [==============================] - 0s 43us/step - loss: 0.2491 - MAE: 77.4211 - val_loss: 0.5547 - val_MAE: 102.0058\n",
      "Epoch 111/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2512 - MAE: 80.2818 - val_loss: 0.5414 - val_MAE: 111.6273\n",
      "Epoch 112/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2554 - MAE: 81.1984 - val_loss: 0.6075 - val_MAE: 112.1278\n",
      "Epoch 113/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2452 - MAE: 80.4957 - val_loss: 0.5071 - val_MAE: 106.6345\n",
      "Epoch 114/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2527 - MAE: 81.5753 - val_loss: 0.6593 - val_MAE: 131.0186\n",
      "Epoch 115/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2509 - MAE: 82.8626 - val_loss: 0.5378 - val_MAE: 101.0482\n",
      "Epoch 116/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2503 - MAE: 79.8090 - val_loss: 0.5856 - val_MAE: 107.0509\n",
      "Epoch 117/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2469 - MAE: 78.9575 - val_loss: 0.5614 - val_MAE: 100.9013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/1000\n",
      "637/637 [==============================] - 0s 48us/step - loss: 0.2477 - MAE: 79.3009 - val_loss: 0.5835 - val_MAE: 106.1218\n",
      "Epoch 119/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2447 - MAE: 78.0098 - val_loss: 0.5869 - val_MAE: 105.1088\n",
      "Epoch 120/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2430 - MAE: 80.4232 - val_loss: 0.5086 - val_MAE: 98.9740\n",
      "Epoch 121/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2442 - MAE: 81.0229 - val_loss: 0.6745 - val_MAE: 139.9586\n",
      "Epoch 122/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2549 - MAE: 78.5853 - val_loss: 0.5717 - val_MAE: 99.4749\n",
      "Epoch 123/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2455 - MAE: 79.4330 - val_loss: 0.5175 - val_MAE: 100.1425\n",
      "Epoch 124/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2573 - MAE: 79.8349 - val_loss: 0.6424 - val_MAE: 116.3747\n",
      "Epoch 125/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2598 - MAE: 84.8729 - val_loss: 0.5386 - val_MAE: 103.1517\n",
      "Epoch 126/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2762 - MAE: 86.5077 - val_loss: 0.5074 - val_MAE: 103.3877\n",
      "Epoch 127/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2497 - MAE: 80.3770 - val_loss: 0.5507 - val_MAE: 98.2811\n",
      "Epoch 128/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2724 - MAE: 85.8784 - val_loss: 0.7158 - val_MAE: 151.6610\n",
      "Epoch 129/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2694 - MAE: 88.7640 - val_loss: 0.5250 - val_MAE: 98.2461\n",
      "Epoch 130/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2462 - MAE: 80.9555 - val_loss: 0.5178 - val_MAE: 99.0906\n",
      "Epoch 131/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2606 - MAE: 86.6186 - val_loss: 0.5646 - val_MAE: 101.2629\n",
      "Epoch 132/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2421 - MAE: 78.9464 - val_loss: 0.5208 - val_MAE: 97.0089\n",
      "Epoch 133/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2479 - MAE: 81.5746 - val_loss: 0.5332 - val_MAE: 98.9964\n",
      "Epoch 134/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2421 - MAE: 75.6072 - val_loss: 0.5939 - val_MAE: 110.8779\n",
      "Epoch 135/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2524 - MAE: 83.1830 - val_loss: 0.5780 - val_MAE: 106.6205\n",
      "Epoch 136/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2432 - MAE: 77.4722 - val_loss: 0.5307 - val_MAE: 99.9576\n",
      "Epoch 137/1000\n",
      "637/637 [==============================] - 0s 43us/step - loss: 0.2417 - MAE: 76.3345 - val_loss: 0.5569 - val_MAE: 99.9649\n",
      "Epoch 138/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2421 - MAE: 78.8509 - val_loss: 0.5166 - val_MAE: 97.2948\n",
      "Epoch 139/1000\n",
      "637/637 [==============================] - 0s 41us/step - loss: 0.2393 - MAE: 79.9771 - val_loss: 0.6248 - val_MAE: 125.4798\n",
      "Epoch 140/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2505 - MAE: 84.8356 - val_loss: 0.5217 - val_MAE: 100.8385\n",
      "Epoch 141/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2396 - MAE: 77.9924 - val_loss: 0.5706 - val_MAE: 108.3970\n",
      "Epoch 142/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2451 - MAE: 80.6979 - val_loss: 0.5165 - val_MAE: 97.2129\n",
      "Epoch 143/1000\n",
      "637/637 [==============================] - 0s 43us/step - loss: 0.2459 - MAE: 79.7476 - val_loss: 0.4947 - val_MAE: 101.0570\n",
      "Epoch 144/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2469 - MAE: 83.6117 - val_loss: 0.5904 - val_MAE: 110.1309\n",
      "Epoch 145/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2444 - MAE: 79.0960 - val_loss: 0.5129 - val_MAE: 101.5382\n",
      "Epoch 146/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2472 - MAE: 78.8844 - val_loss: 0.5197 - val_MAE: 98.2377\n",
      "Epoch 147/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2401 - MAE: 79.4364 - val_loss: 0.5553 - val_MAE: 100.0592\n",
      "Epoch 148/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2441 - MAE: 80.8259 - val_loss: 0.5390 - val_MAE: 98.5715\n",
      "Epoch 149/1000\n",
      "637/637 [==============================] - 0s 50us/step - loss: 0.2393 - MAE: 79.0995 - val_loss: 0.5726 - val_MAE: 105.3150\n",
      "Epoch 150/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2411 - MAE: 75.9923 - val_loss: 0.5431 - val_MAE: 98.5702\n",
      "Epoch 151/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2501 - MAE: 79.0923 - val_loss: 0.5779 - val_MAE: 105.2569\n",
      "Epoch 152/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2504 - MAE: 80.1091 - val_loss: 0.5426 - val_MAE: 100.0192\n",
      "Epoch 153/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2479 - MAE: 81.1506 - val_loss: 0.4967 - val_MAE: 99.0598\n",
      "Epoch 154/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2403 - MAE: 77.3125 - val_loss: 0.5589 - val_MAE: 101.2592\n",
      "Epoch 155/1000\n",
      "637/637 [==============================] - 0s 48us/step - loss: 0.2358 - MAE: 78.8832 - val_loss: 0.5150 - val_MAE: 96.6050\n",
      "Epoch 156/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2345 - MAE: 77.4789 - val_loss: 0.5304 - val_MAE: 98.0928\n",
      "Epoch 157/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2336 - MAE: 78.9978 - val_loss: 0.5543 - val_MAE: 100.2568\n",
      "Epoch 158/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2545 - MAE: 79.6395 - val_loss: 0.5250 - val_MAE: 98.1019\n",
      "Epoch 159/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2729 - MAE: 86.2130 - val_loss: 0.5186 - val_MAE: 107.4656\n",
      "Epoch 160/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2610 - MAE: 81.5528 - val_loss: 0.5931 - val_MAE: 108.3353\n",
      "Epoch 161/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2827 - MAE: 87.4532 - val_loss: 0.5294 - val_MAE: 99.5702\n",
      "Epoch 162/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2389 - MAE: 75.0138 - val_loss: 0.5922 - val_MAE: 103.2032\n",
      "Epoch 163/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.3400 - MAE: 95.9135 - val_loss: 0.8211 - val_MAE: 153.8953\n",
      "Epoch 164/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3647 - MAE: 102.4620 - val_loss: 0.6584 - val_MAE: 113.0723\n",
      "Epoch 165/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.3318 - MAE: 95.6690 - val_loss: 0.6222 - val_MAE: 113.9079\n",
      "Epoch 166/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.3115 - MAE: 87.9678 - val_loss: 0.5957 - val_MAE: 107.0493\n",
      "Epoch 167/1000\n",
      "637/637 [==============================] - 0s 48us/step - loss: 0.3048 - MAE: 90.6846 - val_loss: 0.5762 - val_MAE: 103.2737\n",
      "Epoch 168/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2940 - MAE: 87.8943 - val_loss: 0.6103 - val_MAE: 114.3718\n",
      "Epoch 169/1000\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.2932 - MAE: 88.6098 - val_loss: 0.6489 - val_MAE: 125.4084\n",
      "Epoch 170/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2938 - MAE: 89.4704 - val_loss: 0.6198 - val_MAE: 119.6214\n",
      "Epoch 171/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2951 - MAE: 87.6426 - val_loss: 0.5919 - val_MAE: 107.5853\n",
      "Epoch 172/1000\n",
      "637/637 [==============================] - 0s 49us/step - loss: 0.2876 - MAE: 88.3943 - val_loss: 0.6257 - val_MAE: 121.8526\n",
      "Epoch 173/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2872 - MAE: 87.1308 - val_loss: 0.6273 - val_MAE: 117.4402\n",
      "Epoch 174/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2870 - MAE: 84.9274 - val_loss: 0.5377 - val_MAE: 98.7972\n",
      "Epoch 175/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2831 - MAE: 91.6545 - val_loss: 0.6693 - val_MAE: 136.6304\n",
      "Epoch 176/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2888 - MAE: 85.3819 - val_loss: 0.5814 - val_MAE: 105.4706\n",
      "Epoch 177/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2868 - MAE: 89.5035 - val_loss: 0.7282 - val_MAE: 158.0319\n",
      "Epoch 178/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2820 - MAE: 89.3126 - val_loss: 0.5555 - val_MAE: 100.2566\n",
      "Epoch 179/1000\n",
      "637/637 [==============================] - 0s 46us/step - loss: 0.2770 - MAE: 87.2640 - val_loss: 0.5680 - val_MAE: 101.8226\n",
      "Epoch 180/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2819 - MAE: 87.9479 - val_loss: 0.5077 - val_MAE: 99.9644\n",
      "Epoch 181/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2851 - MAE: 87.9400 - val_loss: 0.5614 - val_MAE: 101.2018\n",
      "Epoch 182/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2799 - MAE: 85.9880 - val_loss: 0.5971 - val_MAE: 111.4888\n",
      "Epoch 183/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2734 - MAE: 82.4904 - val_loss: 0.6114 - val_MAE: 109.5026\n",
      "Epoch 184/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2837 - MAE: 88.6801 - val_loss: 0.5550 - val_MAE: 99.9249\n",
      "Epoch 185/1000\n",
      "637/637 [==============================] - 0s 44us/step - loss: 0.2764 - MAE: 86.8501 - val_loss: 0.5240 - val_MAE: 98.0652\n",
      "Epoch 186/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2857 - MAE: 88.1836 - val_loss: 0.5497 - val_MAE: 99.6372\n",
      "Epoch 187/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2716 - MAE: 84.6303 - val_loss: 0.6168 - val_MAE: 114.8855\n",
      "Epoch 188/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2766 - MAE: 85.0780 - val_loss: 0.5487 - val_MAE: 100.2491\n",
      "Epoch 189/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2686 - MAE: 84.0272 - val_loss: 0.4980 - val_MAE: 101.5590\n",
      "Epoch 190/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2761 - MAE: 89.5881 - val_loss: 0.6403 - val_MAE: 127.3762\n",
      "Epoch 191/1000\n",
      "637/637 [==============================] - 0s 47us/step - loss: 0.2688 - MAE: 83.8964 - val_loss: 0.6267 - val_MAE: 117.4469\n",
      "Epoch 192/1000\n",
      "637/637 [==============================] - 0s 45us/step - loss: 0.2667 - MAE: 85.2581 - val_loss: 0.5938 - val_MAE: 109.2839\n",
      "Epoch 193/1000\n",
      "637/637 [==============================] - 0s 42us/step - loss: 0.2633 - MAE: 83.8939 - val_loss: 0.5993 - val_MAE: 112.3788\n",
      "425/425 [==============================] - 0s 12us/step\n",
      "실제관객:795.000, 예상관객 :505.101\n",
      "실제관객:747.000, 예상관객 :715.736\n",
      "실제관객:711.000, 예상관객 :549.020\n",
      "실제관객:693.000, 예상관객 :417.964\n",
      "실제관객:679.000, 예상관객 :501.170\n",
      "실제관객:664.000, 예상관객 :386.128\n",
      "실제관객:621.000, 예상관객 :648.852\n",
      "실제관객:614.000, 예상관객 :496.002\n",
      "실제관객:599.000, 예상관객 :517.775\n",
      "실제관객:584.000, 예상관객 :424.476\n",
      "425/425 [==============================] - 0s 14us/step\n",
      "\n",
      " Accuracy: 90.3079\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "df = pd.read_excel('./res/데이터/movie_score.xlsx')\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:, 2:8]\n",
    "Y_obj = dataset[:, 1]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "\n",
    "\n",
    "n_fold = 2\n",
    "skf = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = seed)\n",
    "\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for train, test in skf.split(X, Y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=6, activation='relu'))\n",
    "    model.add(Dense(22, activation='relu'))\n",
    "    model.add(Dense(14, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "\n",
    "    model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['MAE'])\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=50)\n",
    "history = model.fit(X,Y, validation_split=0.25, epochs=1000, batch_size=20, callbacks=[early_stopping_callback])\n",
    "\n",
    "k_accuracy = '%.4f' % (model.evaluate(X[test], Y[test])[1])\n",
    "\n",
    "accuracy.append(k_accuracy)\n",
    "\n",
    "Y_prediction = model.predict(X[test]).flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    label = Y[test][i].astype(float)\n",
    "    prediction = Y_prediction[i].astype(float)\n",
    "    print(\"실제관객:%.3f, 예상관객 :%.3f\"%(label, prediction))\n",
    "\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X[test], Y[test])[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019년 12월 제외 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Bigdata\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 630 samples, validate on 211 samples\n",
      "Epoch 1/1000\n",
      "630/630 [==============================] - 0s 202us/step - loss: 1.3159 - MAE: 260.0749 - val_loss: 0.7365 - val_MAE: 127.4506\n",
      "Epoch 2/1000\n",
      "630/630 [==============================] - 0s 80us/step - loss: 0.5752 - MAE: 164.8393 - val_loss: 0.8421 - val_MAE: 131.9605\n",
      "Epoch 3/1000\n",
      "630/630 [==============================] - 0s 42us/step - loss: 0.5639 - MAE: 151.8772 - val_loss: 0.8585 - val_MAE: 134.3002\n",
      "Epoch 4/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.5556 - MAE: 149.6568 - val_loss: 0.8545 - val_MAE: 133.7004\n",
      "Epoch 5/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.5403 - MAE: 148.9580 - val_loss: 0.8590 - val_MAE: 134.4871\n",
      "Epoch 6/1000\n",
      "630/630 [==============================] - 0s 44us/step - loss: 0.5250 - MAE: 142.6598 - val_loss: 0.8706 - val_MAE: 137.4792\n",
      "Epoch 7/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.5134 - MAE: 149.4881 - val_loss: 0.8760 - val_MAE: 139.9767\n",
      "Epoch 8/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.4994 - MAE: 136.1073 - val_loss: 0.8938 - val_MAE: 145.8392\n",
      "Epoch 9/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.4849 - MAE: 141.1506 - val_loss: 0.9025 - val_MAE: 150.1194\n",
      "Epoch 10/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.4715 - MAE: 133.1462 - val_loss: 0.8880 - val_MAE: 149.6060\n",
      "Epoch 11/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.4632 - MAE: 132.4642 - val_loss: 0.8466 - val_MAE: 140.6038\n",
      "Epoch 12/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.4521 - MAE: 135.8591 - val_loss: 0.9332 - val_MAE: 169.8425\n",
      "Epoch 13/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.4494 - MAE: 127.1239 - val_loss: 0.8909 - val_MAE: 158.2002\n",
      "Epoch 14/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.4376 - MAE: 125.0251 - val_loss: 0.8819 - val_MAE: 155.8199\n",
      "Epoch 15/1000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 0.4337 - MAE: 127.2691 - val_loss: 0.8830 - val_MAE: 159.3169\n",
      "Epoch 16/1000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 0.4277 - MAE: 121.9916 - val_loss: 0.8239 - val_MAE: 143.2328\n",
      "Epoch 17/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.4175 - MAE: 123.9850 - val_loss: 0.8961 - val_MAE: 167.6950\n",
      "Epoch 18/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.4135 - MAE: 121.8194 - val_loss: 0.8832 - val_MAE: 167.5392\n",
      "Epoch 19/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.4074 - MAE: 118.3297 - val_loss: 0.8655 - val_MAE: 162.4031\n",
      "Epoch 20/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.4053 - MAE: 117.2883 - val_loss: 0.8092 - val_MAE: 146.9773\n",
      "Epoch 21/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.3978 - MAE: 122.8081 - val_loss: 0.9160 - val_MAE: 183.3112\n",
      "Epoch 22/1000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 0.3896 - MAE: 112.8606 - val_loss: 0.7501 - val_MAE: 133.9642\n",
      "Epoch 23/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3924 - MAE: 116.6939 - val_loss: 0.7989 - val_MAE: 149.6547\n",
      "Epoch 24/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3844 - MAE: 113.1968 - val_loss: 0.8251 - val_MAE: 159.8246\n",
      "Epoch 25/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3829 - MAE: 112.5567 - val_loss: 0.8044 - val_MAE: 155.0047\n",
      "Epoch 26/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3783 - MAE: 111.8258 - val_loss: 0.7925 - val_MAE: 151.2864\n",
      "Epoch 27/1000\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.8710 - MAE: 142.802 - 0s 51us/step - loss: 0.3789 - MAE: 111.0611 - val_loss: 0.6848 - val_MAE: 120.4065\n",
      "Epoch 28/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.3740 - MAE: 109.5938 - val_loss: 0.7885 - val_MAE: 152.9004\n",
      "Epoch 29/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3710 - MAE: 109.4875 - val_loss: 0.8017 - val_MAE: 158.3386\n",
      "Epoch 30/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.3680 - MAE: 106.3112 - val_loss: 0.6966 - val_MAE: 125.1205\n",
      "Epoch 31/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3650 - MAE: 108.9145 - val_loss: 0.7916 - val_MAE: 158.1695\n",
      "Epoch 32/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3647 - MAE: 107.8307 - val_loss: 0.7235 - val_MAE: 133.7508\n",
      "Epoch 33/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.3568 - MAE: 106.1195 - val_loss: 0.7003 - val_MAE: 128.4904\n",
      "Epoch 34/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3578 - MAE: 101.8160 - val_loss: 0.6892 - val_MAE: 126.1480\n",
      "Epoch 35/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.3528 - MAE: 104.3232 - val_loss: 0.7358 - val_MAE: 140.2493\n",
      "Epoch 36/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3564 - MAE: 105.3780 - val_loss: 0.7366 - val_MAE: 141.4952\n",
      "Epoch 37/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3494 - MAE: 99.3636 - val_loss: 0.6354 - val_MAE: 111.4851\n",
      "Epoch 38/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3579 - MAE: 104.4124 - val_loss: 0.6858 - val_MAE: 124.2026\n",
      "Epoch 39/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3459 - MAE: 102.1726 - val_loss: 0.6920 - val_MAE: 128.3928\n",
      "Epoch 40/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3476 - MAE: 101.8015 - val_loss: 0.6869 - val_MAE: 126.3425\n",
      "Epoch 41/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3392 - MAE: 100.4590 - val_loss: 0.6626 - val_MAE: 118.8017\n",
      "Epoch 42/1000\n",
      "630/630 [==============================] - 0s 44us/step - loss: 0.3365 - MAE: 99.3008 - val_loss: 0.6436 - val_MAE: 113.9358\n",
      "Epoch 43/1000\n",
      "630/630 [==============================] - 0s 42us/step - loss: 0.3341 - MAE: 100.7047 - val_loss: 0.7629 - val_MAE: 153.5446\n",
      "Epoch 44/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.3395 - MAE: 101.1144 - val_loss: 0.7698 - val_MAE: 156.5034\n",
      "Epoch 45/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.3374 - MAE: 98.1281 - val_loss: 0.7299 - val_MAE: 141.4077\n",
      "Epoch 46/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.3375 - MAE: 99.6802 - val_loss: 0.7103 - val_MAE: 137.0836\n",
      "Epoch 47/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.3301 - MAE: 94.9653 - val_loss: 0.7433 - val_MAE: 150.1824\n",
      "Epoch 48/1000\n",
      "630/630 [==============================] - 0s 44us/step - loss: 0.3383 - MAE: 98.2638 - val_loss: 0.6876 - val_MAE: 127.5560\n",
      "Epoch 49/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.3232 - MAE: 96.1776 - val_loss: 0.6310 - val_MAE: 112.8980\n",
      "Epoch 50/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.3272 - MAE: 95.9752 - val_loss: 0.6106 - val_MAE: 107.6881\n",
      "Epoch 51/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.3200 - MAE: 92.6985 - val_loss: 0.6463 - val_MAE: 117.0688\n",
      "Epoch 52/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.3327 - MAE: 95.5967 - val_loss: 0.6574 - val_MAE: 117.9532\n",
      "Epoch 53/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.3341 - MAE: 100.8428 - val_loss: 0.6162 - val_MAE: 111.0140\n",
      "Epoch 54/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.3159 - MAE: 94.3181 - val_loss: 0.6195 - val_MAE: 110.5457\n",
      "Epoch 55/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.3172 - MAE: 93.9152 - val_loss: 0.6548 - val_MAE: 120.5757\n",
      "Epoch 56/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.3161 - MAE: 91.0003 - val_loss: 0.6624 - val_MAE: 122.4636\n",
      "Epoch 57/1000\n",
      "630/630 [==============================] - 0s 44us/step - loss: 0.3219 - MAE: 96.3124 - val_loss: 0.6193 - val_MAE: 112.0071\n",
      "Epoch 58/1000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 0.3120 - MAE: 92.2346 - val_loss: 0.6449 - val_MAE: 119.4864\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 50us/step - loss: 0.3041 - MAE: 90.8025 - val_loss: 0.6114 - val_MAE: 111.0528\n",
      "Epoch 60/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.3050 - MAE: 92.6247 - val_loss: 0.6079 - val_MAE: 109.8962\n",
      "Epoch 61/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3046 - MAE: 89.0125 - val_loss: 0.5650 - val_MAE: 101.9418\n",
      "Epoch 62/1000\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1579 - MAE: 82.43 - 0s 48us/step - loss: 0.3169 - MAE: 97.1919 - val_loss: 0.9253 - val_MAE: 229.5743\n",
      "Epoch 63/1000\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1042 - MAE: 103.586 - 0s 51us/step - loss: 0.3287 - MAE: 98.8941 - val_loss: 0.5989 - val_MAE: 106.9017\n",
      "Epoch 64/1000\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1794 - MAE: 103.574 - 0s 49us/step - loss: 0.3111 - MAE: 94.1593 - val_loss: 0.6374 - val_MAE: 118.5370\n",
      "Epoch 65/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.3038 - MAE: 90.7105 - val_loss: 0.6787 - val_MAE: 132.3278\n",
      "Epoch 66/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2974 - MAE: 91.5325 - val_loss: 0.6919 - val_MAE: 136.7417\n",
      "Epoch 67/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2957 - MAE: 87.0470 - val_loss: 0.5946 - val_MAE: 106.7629\n",
      "Epoch 68/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2926 - MAE: 89.2688 - val_loss: 0.7506 - val_MAE: 163.2372\n",
      "Epoch 69/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2946 - MAE: 89.6555 - val_loss: 0.5426 - val_MAE: 98.1031\n",
      "Epoch 70/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2999 - MAE: 86.1433 - val_loss: 0.4999 - val_MAE: 110.7891\n",
      "Epoch 71/1000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 0.3061 - MAE: 94.7018 - val_loss: 0.5149 - val_MAE: 100.1853\n",
      "Epoch 72/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2917 - MAE: 93.2215 - val_loss: 0.5676 - val_MAE: 102.3013\n",
      "Epoch 73/1000\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.9821 - MAE: 84.46 - 0s 49us/step - loss: 0.2894 - MAE: 86.8134 - val_loss: 0.6501 - val_MAE: 124.0526\n",
      "Epoch 74/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2857 - MAE: 87.5918 - val_loss: 0.6218 - val_MAE: 113.5849\n",
      "Epoch 75/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.2803 - MAE: 84.8776 - val_loss: 0.6047 - val_MAE: 108.3468\n",
      "Epoch 76/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2950 - MAE: 87.5680 - val_loss: 0.7127 - val_MAE: 145.5438\n",
      "Epoch 77/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2944 - MAE: 93.5535 - val_loss: 0.5725 - val_MAE: 104.1580\n",
      "Epoch 78/1000\n",
      "630/630 [==============================] - 0s 45us/step - loss: 0.2785 - MAE: 84.1830 - val_loss: 0.5844 - val_MAE: 103.5522\n",
      "Epoch 79/1000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 0.2769 - MAE: 85.4428 - val_loss: 0.5893 - val_MAE: 105.0245\n",
      "Epoch 80/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2691 - MAE: 82.8373 - val_loss: 0.5935 - val_MAE: 106.0600\n",
      "Epoch 81/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2826 - MAE: 87.7981 - val_loss: 0.5562 - val_MAE: 98.7660\n",
      "Epoch 82/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2657 - MAE: 84.2060 - val_loss: 0.5144 - val_MAE: 99.7240\n",
      "Epoch 83/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.2830 - MAE: 82.2963 - val_loss: 0.5978 - val_MAE: 107.9643\n",
      "Epoch 84/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2747 - MAE: 86.6935 - val_loss: 0.5352 - val_MAE: 98.3454\n",
      "Epoch 85/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2772 - MAE: 86.4112 - val_loss: 0.6585 - val_MAE: 129.7923\n",
      "Epoch 86/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2633 - MAE: 80.4944 - val_loss: 0.5641 - val_MAE: 99.6612\n",
      "Epoch 87/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2708 - MAE: 86.4981 - val_loss: 0.6088 - val_MAE: 110.1420\n",
      "Epoch 88/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2651 - MAE: 80.9751 - val_loss: 0.5503 - val_MAE: 100.5574\n",
      "Epoch 89/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2644 - MAE: 82.8770 - val_loss: 0.5942 - val_MAE: 105.1139\n",
      "Epoch 90/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2736 - MAE: 84.1366 - val_loss: 0.6620 - val_MAE: 127.1080\n",
      "Epoch 91/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2664 - MAE: 83.0478 - val_loss: 0.5828 - val_MAE: 103.1312\n",
      "Epoch 92/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2571 - MAE: 78.7831 - val_loss: 0.5649 - val_MAE: 99.5713\n",
      "Epoch 93/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2577 - MAE: 83.2673 - val_loss: 0.5418 - val_MAE: 96.1048\n",
      "Epoch 94/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2581 - MAE: 83.1405 - val_loss: 0.5036 - val_MAE: 100.2515\n",
      "Epoch 95/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.2614 - MAE: 82.2703 - val_loss: 0.5538 - val_MAE: 97.5405\n",
      "Epoch 96/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2585 - MAE: 81.0148 - val_loss: 0.6680 - val_MAE: 134.6936\n",
      "Epoch 97/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2555 - MAE: 79.1185 - val_loss: 0.5930 - val_MAE: 105.2384\n",
      "Epoch 98/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2480 - MAE: 79.4724 - val_loss: 0.5231 - val_MAE: 97.8208\n",
      "Epoch 99/1000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 0.2504 - MAE: 81.7308 - val_loss: 0.5521 - val_MAE: 99.0889\n",
      "Epoch 100/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2448 - MAE: 78.9177 - val_loss: 0.6029 - val_MAE: 109.6233\n",
      "Epoch 101/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2538 - MAE: 76.1588 - val_loss: 0.5385 - val_MAE: 96.8887\n",
      "Epoch 102/1000\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.0973 - MAE: 56.35 - 0s 48us/step - loss: 0.2528 - MAE: 82.0011 - val_loss: 0.5574 - val_MAE: 98.9582\n",
      "Epoch 103/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2462 - MAE: 77.0727 - val_loss: 0.5533 - val_MAE: 97.5267\n",
      "Epoch 104/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2510 - MAE: 78.5816 - val_loss: 0.6685 - val_MAE: 135.1017\n",
      "Epoch 105/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2669 - MAE: 84.7739 - val_loss: 0.6076 - val_MAE: 112.1959\n",
      "Epoch 106/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2481 - MAE: 75.7530 - val_loss: 0.5514 - val_MAE: 96.6460\n",
      "Epoch 107/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.2464 - MAE: 80.2723 - val_loss: 0.5156 - val_MAE: 97.4156\n",
      "Epoch 108/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2470 - MAE: 78.0790 - val_loss: 0.5791 - val_MAE: 103.4943\n",
      "Epoch 109/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2451 - MAE: 78.5892 - val_loss: 0.5649 - val_MAE: 100.3042\n",
      "Epoch 110/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2427 - MAE: 76.2243 - val_loss: 0.5936 - val_MAE: 107.6515\n",
      "Epoch 111/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.2417 - MAE: 77.2123 - val_loss: 0.5153 - val_MAE: 99.4147\n",
      "Epoch 112/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2488 - MAE: 79.7597 - val_loss: 0.4995 - val_MAE: 97.1932\n",
      "Epoch 113/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2391 - MAE: 83.3071 - val_loss: 0.5382 - val_MAE: 98.9667\n",
      "Epoch 114/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2494 - MAE: 78.4684 - val_loss: 0.5155 - val_MAE: 106.2460\n",
      "Epoch 115/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2412 - MAE: 78.9099 - val_loss: 0.5118 - val_MAE: 100.9935\n",
      "Epoch 116/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2435 - MAE: 78.0281 - val_loss: 0.5788 - val_MAE: 101.8057\n",
      "Epoch 117/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.2545 - MAE: 80.3796 - val_loss: 0.5216 - val_MAE: 94.5036\n",
      "Epoch 118/1000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 0.2384 - MAE: 76.5113 - val_loss: 0.5259 - val_MAE: 98.1914\n",
      "Epoch 119/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2395 - MAE: 77.0064 - val_loss: 0.5327 - val_MAE: 96.1424\n",
      "Epoch 120/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2371 - MAE: 78.4634 - val_loss: 0.6465 - val_MAE: 124.6468\n",
      "Epoch 121/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2492 - MAE: 82.9003 - val_loss: 0.6565 - val_MAE: 125.0747\n",
      "Epoch 122/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2451 - MAE: 78.3971 - val_loss: 0.5026 - val_MAE: 106.2890\n",
      "Epoch 123/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.2416 - MAE: 79.4909 - val_loss: 0.6757 - val_MAE: 140.5486\n",
      "Epoch 124/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2528 - MAE: 82.2152 - val_loss: 0.5231 - val_MAE: 95.7213\n",
      "Epoch 125/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2362 - MAE: 75.4143 - val_loss: 0.5237 - val_MAE: 94.8549\n",
      "Epoch 126/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.2365 - MAE: 77.8081 - val_loss: 0.5423 - val_MAE: 97.2744\n",
      "Epoch 127/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2347 - MAE: 76.8592 - val_loss: 0.5185 - val_MAE: 96.0056\n",
      "Epoch 128/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2454 - MAE: 79.5171 - val_loss: 0.6519 - val_MAE: 134.8812\n",
      "Epoch 129/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2514 - MAE: 80.0100 - val_loss: 0.5739 - val_MAE: 110.9596\n",
      "Epoch 130/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.2447 - MAE: 78.2407 - val_loss: 0.5331 - val_MAE: 97.8749\n",
      "Epoch 131/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2437 - MAE: 78.5135 - val_loss: 0.6083 - val_MAE: 113.5908\n",
      "Epoch 132/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2381 - MAE: 78.4999 - val_loss: 0.5230 - val_MAE: 96.5818\n",
      "Epoch 133/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2340 - MAE: 77.2689 - val_loss: 0.5072 - val_MAE: 93.2429\n",
      "Epoch 134/1000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 0.2509 - MAE: 83.2170 - val_loss: 0.5875 - val_MAE: 106.8891\n",
      "Epoch 135/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2392 - MAE: 75.3337 - val_loss: 0.5249 - val_MAE: 94.4247\n",
      "Epoch 136/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2301 - MAE: 76.1248 - val_loss: 0.6296 - val_MAE: 122.9711\n",
      "Epoch 137/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2635 - MAE: 81.9415 - val_loss: 0.8222 - val_MAE: 190.9821\n",
      "Epoch 138/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.2733 - MAE: 83.0095 - val_loss: 0.4974 - val_MAE: 105.3612\n",
      "Epoch 139/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2466 - MAE: 82.2171 - val_loss: 0.5572 - val_MAE: 101.2873\n",
      "Epoch 140/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.2388 - MAE: 76.7779 - val_loss: 0.5384 - val_MAE: 100.6360\n",
      "Epoch 141/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.2990 - MAE: 95.2885 - val_loss: 0.7515 - val_MAE: 144.4477\n",
      "Epoch 142/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.3086 - MAE: 101.0207 - val_loss: 0.6903 - val_MAE: 135.9549\n",
      "Epoch 143/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2610 - MAE: 83.9340 - val_loss: 0.5476 - val_MAE: 99.4781\n",
      "Epoch 144/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2723 - MAE: 83.0647 - val_loss: 0.5174 - val_MAE: 100.8927\n",
      "Epoch 145/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2542 - MAE: 79.4889 - val_loss: 0.6474 - val_MAE: 121.4074\n",
      "Epoch 146/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2494 - MAE: 79.8242 - val_loss: 0.6084 - val_MAE: 109.0188\n",
      "Epoch 147/1000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 0.2536 - MAE: 79.4524 - val_loss: 0.6995 - val_MAE: 149.6140\n",
      "Epoch 148/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2593 - MAE: 78.2271 - val_loss: 0.6337 - val_MAE: 110.2917\n",
      "Epoch 149/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2496 - MAE: 84.5495 - val_loss: 0.5490 - val_MAE: 102.2925\n",
      "Epoch 150/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2454 - MAE: 76.7388 - val_loss: 0.5340 - val_MAE: 102.2290\n",
      "Epoch 151/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.2376 - MAE: 78.0989 - val_loss: 0.5343 - val_MAE: 97.6225\n",
      "Epoch 152/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2351 - MAE: 78.6400 - val_loss: 0.5653 - val_MAE: 100.9456\n",
      "Epoch 153/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2326 - MAE: 76.4386 - val_loss: 0.4843 - val_MAE: 101.7539\n",
      "Epoch 154/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2333 - MAE: 76.0034 - val_loss: 0.5304 - val_MAE: 96.7233\n",
      "Epoch 155/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2319 - MAE: 80.2343 - val_loss: 0.5807 - val_MAE: 104.2695\n",
      "Epoch 156/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2387 - MAE: 74.2751 - val_loss: 0.5175 - val_MAE: 99.7117\n",
      "Epoch 157/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2328 - MAE: 80.1780 - val_loss: 0.6196 - val_MAE: 116.4244\n",
      "Epoch 158/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2421 - MAE: 79.4122 - val_loss: 0.5381 - val_MAE: 93.9966\n",
      "Epoch 159/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2340 - MAE: 73.1744 - val_loss: 0.5806 - val_MAE: 103.1207\n",
      "Epoch 160/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2542 - MAE: 84.4875 - val_loss: 0.5368 - val_MAE: 95.2041\n",
      "Epoch 161/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2338 - MAE: 75.7457 - val_loss: 0.5743 - val_MAE: 105.6092\n",
      "Epoch 162/1000\n",
      "630/630 [==============================] - 0s 45us/step - loss: 0.2329 - MAE: 77.3155 - val_loss: 0.5607 - val_MAE: 100.3334\n",
      "Epoch 163/1000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 0.2487 - MAE: 74.9919 - val_loss: 0.8190 - val_MAE: 188.0623\n",
      "Epoch 164/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3051 - MAE: 96.4350 - val_loss: 0.6047 - val_MAE: 107.0799\n",
      "Epoch 165/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2587 - MAE: 80.8219 - val_loss: 0.5343 - val_MAE: 94.0019\n",
      "Epoch 166/1000\n",
      "630/630 [==============================] - 0s 44us/step - loss: 0.2402 - MAE: 77.2580 - val_loss: 0.6447 - val_MAE: 104.6613\n",
      "Epoch 167/1000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 0.2576 - MAE: 79.4170 - val_loss: 0.5220 - val_MAE: 91.8419\n",
      "Epoch 168/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2632 - MAE: 82.9802 - val_loss: 0.6286 - val_MAE: 106.5998\n",
      "Epoch 169/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2678 - MAE: 87.4733 - val_loss: 0.5542 - val_MAE: 101.2986\n",
      "Epoch 170/1000\n",
      "630/630 [==============================] - 0s 45us/step - loss: 0.2446 - MAE: 80.7478 - val_loss: 0.5769 - val_MAE: 105.9846\n",
      "Epoch 171/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2385 - MAE: 75.2381 - val_loss: 0.6310 - val_MAE: 114.2989\n",
      "Epoch 172/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2631 - MAE: 82.6981 - val_loss: 0.5365 - val_MAE: 94.9392\n",
      "Epoch 173/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2429 - MAE: 79.8367 - val_loss: 0.5005 - val_MAE: 100.6374\n",
      "Epoch 174/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2540 - MAE: 82.4347 - val_loss: 0.4919 - val_MAE: 94.9699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 0.2396 - MAE: 78.6236 - val_loss: 0.5507 - val_MAE: 100.5283\n",
      "Epoch 176/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2401 - MAE: 77.2476 - val_loss: 0.4669 - val_MAE: 102.2506\n",
      "Epoch 177/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2423 - MAE: 82.1685 - val_loss: 0.4723 - val_MAE: 100.0554\n",
      "Epoch 178/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2397 - MAE: 79.5355 - val_loss: 0.4958 - val_MAE: 95.2719\n",
      "Epoch 179/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2334 - MAE: 78.8534 - val_loss: 0.5772 - val_MAE: 102.1452\n",
      "Epoch 180/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2406 - MAE: 77.3966 - val_loss: 0.5153 - val_MAE: 98.2466\n",
      "Epoch 181/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2770 - MAE: 79.9405 - val_loss: 0.8736 - val_MAE: 190.9158\n",
      "Epoch 182/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.3724 - MAE: 101.7941 - val_loss: 0.6792 - val_MAE: 114.3376\n",
      "Epoch 183/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.3048 - MAE: 92.0273 - val_loss: 0.5898 - val_MAE: 100.9456\n",
      "Epoch 184/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2597 - MAE: 83.4258 - val_loss: 0.5587 - val_MAE: 101.0972\n",
      "Epoch 185/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2459 - MAE: 85.8151 - val_loss: 0.6161 - val_MAE: 117.1165\n",
      "Epoch 186/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2376 - MAE: 78.3504 - val_loss: 0.5552 - val_MAE: 101.0423\n",
      "Epoch 187/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2334 - MAE: 78.3137 - val_loss: 0.5336 - val_MAE: 94.4578\n",
      "Epoch 188/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2309 - MAE: 76.3943 - val_loss: 0.5573 - val_MAE: 98.7994\n",
      "Epoch 189/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2303 - MAE: 78.1843 - val_loss: 0.5621 - val_MAE: 99.8087\n",
      "Epoch 190/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2280 - MAE: 76.4709 - val_loss: 0.5820 - val_MAE: 106.3269\n",
      "Epoch 191/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.2318 - MAE: 75.7560 - val_loss: 0.5269 - val_MAE: 94.2688\n",
      "Epoch 192/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2324 - MAE: 79.0202 - val_loss: 0.5166 - val_MAE: 94.3152\n",
      "Epoch 193/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2309 - MAE: 78.4119 - val_loss: 0.5391 - val_MAE: 95.8169\n",
      "Epoch 194/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2275 - MAE: 76.9777 - val_loss: 0.5214 - val_MAE: 95.3003\n",
      "Epoch 195/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2428 - MAE: 75.8684 - val_loss: 0.4939 - val_MAE: 96.4393\n",
      "Epoch 196/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2281 - MAE: 78.4434 - val_loss: 0.5299 - val_MAE: 93.3826\n",
      "Epoch 197/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2292 - MAE: 78.0669 - val_loss: 0.5509 - val_MAE: 97.7615\n",
      "Epoch 198/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2315 - MAE: 73.6350 - val_loss: 0.5295 - val_MAE: 94.7521\n",
      "Epoch 199/1000\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1835 - MAE: 77.81 - 0s 48us/step - loss: 0.2315 - MAE: 78.7005 - val_loss: 0.5417 - val_MAE: 95.7147\n",
      "Epoch 200/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2261 - MAE: 73.8005 - val_loss: 0.5143 - val_MAE: 93.1784\n",
      "Epoch 201/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.2283 - MAE: 76.5343 - val_loss: 0.5356 - val_MAE: 93.4756\n",
      "Epoch 202/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2251 - MAE: 77.5153 - val_loss: 0.5439 - val_MAE: 95.3046\n",
      "Epoch 203/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2247 - MAE: 76.5881 - val_loss: 0.5789 - val_MAE: 103.2597\n",
      "Epoch 204/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2248 - MAE: 74.6550 - val_loss: 0.5483 - val_MAE: 95.0318\n",
      "Epoch 205/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2226 - MAE: 76.7401 - val_loss: 0.6234 - val_MAE: 119.4921\n",
      "Epoch 206/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2299 - MAE: 76.7687 - val_loss: 0.4955 - val_MAE: 97.5715\n",
      "Epoch 207/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2285 - MAE: 76.1070 - val_loss: 0.5134 - val_MAE: 92.5378\n",
      "Epoch 208/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2267 - MAE: 76.8690 - val_loss: 0.5147 - val_MAE: 91.9418\n",
      "Epoch 209/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.3704 - MAE: 108.6259 - val_loss: 0.7436 - val_MAE: 130.3629\n",
      "Epoch 210/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.3243 - MAE: 102.4062 - val_loss: 0.6403 - val_MAE: 114.2075\n",
      "Epoch 211/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2807 - MAE: 87.1494 - val_loss: 0.5589 - val_MAE: 104.4072\n",
      "Epoch 212/1000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 0.2579 - MAE: 84.9026 - val_loss: 0.5350 - val_MAE: 101.0001\n",
      "Epoch 213/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2486 - MAE: 80.3954 - val_loss: 0.5719 - val_MAE: 104.4303\n",
      "Epoch 214/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2473 - MAE: 83.4159 - val_loss: 0.5393 - val_MAE: 97.7627\n",
      "Epoch 215/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.2389 - MAE: 77.8015 - val_loss: 0.5201 - val_MAE: 96.5683\n",
      "Epoch 216/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 0.2374 - MAE: 80.1373 - val_loss: 0.5006 - val_MAE: 94.3334\n",
      "Epoch 217/1000\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1229 - MAE: 80.51 - 0s 63us/step - loss: 0.2385 - MAE: 78.6833 - val_loss: 0.5559 - val_MAE: 98.5426\n",
      "Epoch 218/1000\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.0518 - MAE: 66.27 - 0s 49us/step - loss: 0.2342 - MAE: 78.6278 - val_loss: 0.5339 - val_MAE: 96.0324\n",
      "Epoch 219/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2328 - MAE: 77.3100 - val_loss: 0.5262 - val_MAE: 93.2043\n",
      "Epoch 220/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2271 - MAE: 75.5103 - val_loss: 0.5278 - val_MAE: 94.8414\n",
      "Epoch 221/1000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 0.2302 - MAE: 79.1623 - val_loss: 0.5352 - val_MAE: 93.0718\n",
      "Epoch 222/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2268 - MAE: 75.0636 - val_loss: 0.5327 - val_MAE: 92.0136\n",
      "Epoch 223/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2259 - MAE: 76.2879 - val_loss: 0.5362 - val_MAE: 94.6284\n",
      "Epoch 224/1000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 0.2236 - MAE: 75.2230 - val_loss: 0.5323 - val_MAE: 93.8122\n",
      "Epoch 225/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.2388 - MAE: 78.0940 - val_loss: 0.6001 - val_MAE: 111.5771\n",
      "Epoch 226/1000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 0.2574 - MAE: 83.1982 - val_loss: 0.5832 - val_MAE: 113.7483\n",
      "420/420 [==============================] - 0s 12us/step\n",
      "실제관객:787.000, 예상관객 :557.029\n",
      "실제관객:739.000, 예상관객 :761.856\n",
      "실제관객:703.000, 예상관객 :559.824\n",
      "실제관객:685.000, 예상관객 :489.537\n",
      "실제관객:671.000, 예상관객 :532.524\n",
      "실제관객:656.000, 예상관객 :410.538\n",
      "실제관객:614.000, 예상관객 :671.079\n",
      "실제관객:607.000, 예상관객 :540.064\n",
      "실제관객:592.000, 예상관객 :543.374\n",
      "실제관객:577.000, 예상관객 :457.415\n",
      "420/420 [==============================] - 0s 12us/step\n",
      "\n",
      " Accuracy: 83.6909\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "df = pd.read_excel('./res/데이터/movie_score_re.xlsx')\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:, 2:8]\n",
    "Y_obj = dataset[:, 1]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "\n",
    "n_fold = 2\n",
    "skf = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = seed)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for train, test in skf.split(X, Y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=6, activation='relu'))\n",
    "    model.add(Dense(22, activation='relu'))\n",
    "    model.add(Dense(14, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['MAE'])\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=50)\n",
    "history = model.fit(X,Y, validation_split=0.25, epochs=1000, batch_size=20, callbacks=[early_stopping_callback])\n",
    "\n",
    "k_accuracy = '%.4f' % (model.evaluate(X[test], Y[test])[1])\n",
    "\n",
    "accuracy.append(k_accuracy)\n",
    "\n",
    "Y_prediction = model.predict(X[test]).flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    label = Y[test][i].astype(float)\n",
    "    prediction = Y_prediction[i].astype(float)\n",
    "    print(\"실제관객:%.3f, 예상관객 :%.3f\"%(label, prediction))\n",
    "\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X[test], Y[test])[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8/3 최종"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 630 samples, validate on 211 samples\n",
      "Epoch 1/1000\n",
      "630/630 [==============================] - 0s 182us/step - loss: 0.7518 - MAE: 0.6374 - val_loss: 0.7372 - val_MAE: 0.6861\n",
      "Epoch 2/1000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 0.4767 - MAE: 0.4659 - val_loss: 0.6997 - val_MAE: 0.6630\n",
      "Epoch 3/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 0.3981 - MAE: 0.4151 - val_loss: 0.6834 - val_MAE: 0.6421\n",
      "Epoch 4/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 0.3582 - MAE: 0.3858 - val_loss: 0.7357 - val_MAE: 0.6705\n",
      "Epoch 5/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 0.3391 - MAE: 0.3691 - val_loss: 0.6729 - val_MAE: 0.6238\n",
      "Epoch 6/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 0.3247 - MAE: 0.3479 - val_loss: 0.6742 - val_MAE: 0.6226\n",
      "Epoch 7/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.3119 - MAE: 0.3443 - val_loss: 0.6851 - val_MAE: 0.6186\n",
      "Epoch 8/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.3019 - MAE: 0.3348 - val_loss: 0.6376 - val_MAE: 0.5849\n",
      "Epoch 9/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2929 - MAE: 0.3222 - val_loss: 0.6291 - val_MAE: 0.5745\n",
      "Epoch 10/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2854 - MAE: 0.3242 - val_loss: 0.6320 - val_MAE: 0.5688\n",
      "Epoch 11/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2777 - MAE: 0.3113 - val_loss: 0.6554 - val_MAE: 0.5809\n",
      "Epoch 12/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2723 - MAE: 0.3159 - val_loss: 0.6019 - val_MAE: 0.5362\n",
      "Epoch 13/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2698 - MAE: 0.3043 - val_loss: 0.6139 - val_MAE: 0.5487\n",
      "Epoch 14/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 0.2659 - MAE: 0.3075 - val_loss: 0.5704 - val_MAE: 0.5099\n",
      "Epoch 15/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2590 - MAE: 0.2980 - val_loss: 0.6036 - val_MAE: 0.5334\n",
      "Epoch 16/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2523 - MAE: 0.2973 - val_loss: 0.6044 - val_MAE: 0.5267\n",
      "Epoch 17/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2497 - MAE: 0.2946 - val_loss: 0.6102 - val_MAE: 0.5254\n",
      "Epoch 18/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 0.2471 - MAE: 0.2925 - val_loss: 0.6104 - val_MAE: 0.5219\n",
      "Epoch 19/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2438 - MAE: 0.2927 - val_loss: 0.5859 - val_MAE: 0.5046\n",
      "Epoch 20/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 0.2456 - MAE: 0.2890 - val_loss: 0.6412 - val_MAE: 0.5332\n",
      "Epoch 21/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2433 - MAE: 0.2932 - val_loss: 0.5707 - val_MAE: 0.4902\n",
      "Epoch 22/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 0.2419 - MAE: 0.2844 - val_loss: 0.6119 - val_MAE: 0.5163\n",
      "Epoch 23/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2404 - MAE: 0.2886 - val_loss: 0.5479 - val_MAE: 0.4657\n",
      "Epoch 24/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2373 - MAE: 0.2833 - val_loss: 0.5571 - val_MAE: 0.4749\n",
      "Epoch 25/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2330 - MAE: 0.2804 - val_loss: 0.6007 - val_MAE: 0.5012\n",
      "Epoch 26/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2331 - MAE: 0.2842 - val_loss: 0.5551 - val_MAE: 0.4693\n",
      "Epoch 27/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2311 - MAE: 0.2775 - val_loss: 0.5838 - val_MAE: 0.4885\n",
      "Epoch 28/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2353 - MAE: 0.2818 - val_loss: 0.5355 - val_MAE: 0.4530\n",
      "Epoch 29/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2288 - MAE: 0.2756 - val_loss: 0.5934 - val_MAE: 0.4887\n",
      "Epoch 30/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2274 - MAE: 0.2757 - val_loss: 0.5705 - val_MAE: 0.4719\n",
      "Epoch 31/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2249 - MAE: 0.2745 - val_loss: 0.5823 - val_MAE: 0.4798\n",
      "Epoch 32/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2235 - MAE: 0.2733 - val_loss: 0.5792 - val_MAE: 0.4752\n",
      "Epoch 33/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2249 - MAE: 0.2742 - val_loss: 0.5823 - val_MAE: 0.4775\n",
      "Epoch 34/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 0.2231 - MAE: 0.2706 - val_loss: 0.5557 - val_MAE: 0.4594\n",
      "Epoch 35/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2210 - MAE: 0.2709 - val_loss: 0.5552 - val_MAE: 0.4597\n",
      "Epoch 36/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2203 - MAE: 0.2698 - val_loss: 0.5789 - val_MAE: 0.4754\n",
      "Epoch 37/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2238 - MAE: 0.2741 - val_loss: 0.5410 - val_MAE: 0.4443\n",
      "Epoch 38/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2181 - MAE: 0.2697 - val_loss: 0.5725 - val_MAE: 0.4622\n",
      "Epoch 39/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2199 - MAE: 0.2686 - val_loss: 0.5640 - val_MAE: 0.4600\n",
      "Epoch 40/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2165 - MAE: 0.2674 - val_loss: 0.5799 - val_MAE: 0.4681\n",
      "Epoch 41/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2166 - MAE: 0.2688 - val_loss: 0.5337 - val_MAE: 0.4371\n",
      "Epoch 42/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2198 - MAE: 0.2694 - val_loss: 0.5685 - val_MAE: 0.4630\n",
      "Epoch 43/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2135 - MAE: 0.2653 - val_loss: 0.5542 - val_MAE: 0.4515\n",
      "Epoch 44/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2128 - MAE: 0.2654 - val_loss: 0.5835 - val_MAE: 0.4690\n",
      "Epoch 45/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2187 - MAE: 0.2702 - val_loss: 0.6053 - val_MAE: 0.4762\n",
      "Epoch 46/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2115 - MAE: 0.2641 - val_loss: 0.5626 - val_MAE: 0.4525\n",
      "Epoch 47/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2121 - MAE: 0.2634 - val_loss: 0.5624 - val_MAE: 0.4578\n",
      "Epoch 48/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2113 - MAE: 0.2677 - val_loss: 0.5473 - val_MAE: 0.4425\n",
      "Epoch 49/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2096 - MAE: 0.2618 - val_loss: 0.5477 - val_MAE: 0.4481\n",
      "Epoch 50/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2079 - MAE: 0.2609 - val_loss: 0.6233 - val_MAE: 0.4870\n",
      "Epoch 51/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2129 - MAE: 0.2721 - val_loss: 0.5150 - val_MAE: 0.4242\n",
      "Epoch 52/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 0.2080 - MAE: 0.2640 - val_loss: 0.5874 - val_MAE: 0.4668\n",
      "Epoch 53/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2036 - MAE: 0.2608 - val_loss: 0.5385 - val_MAE: 0.4329\n",
      "Epoch 54/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2046 - MAE: 0.2596 - val_loss: 0.5856 - val_MAE: 0.4688\n",
      "Epoch 55/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2082 - MAE: 0.2637 - val_loss: 0.5492 - val_MAE: 0.4450\n",
      "Epoch 56/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.2069 - MAE: 0.2619 - val_loss: 0.5783 - val_MAE: 0.4638\n",
      "Epoch 57/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2033 - MAE: 0.2609 - val_loss: 0.5344 - val_MAE: 0.4283\n",
      "Epoch 58/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2044 - MAE: 0.2618 - val_loss: 0.5518 - val_MAE: 0.4386\n",
      "Epoch 59/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.2022 - MAE: 0.2594 - val_loss: 0.5922 - val_MAE: 0.4659\n",
      "Epoch 60/1000\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2127 - MAE: 0.261 - 0s 41us/step - loss: 0.2031 - MAE: 0.2612 - val_loss: 0.5729 - val_MAE: 0.4550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1983 - MAE: 0.2573 - val_loss: 0.5648 - val_MAE: 0.4509\n",
      "Epoch 62/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1982 - MAE: 0.2581 - val_loss: 0.5671 - val_MAE: 0.4471\n",
      "Epoch 63/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 0.1967 - MAE: 0.2566 - val_loss: 0.5707 - val_MAE: 0.4543\n",
      "Epoch 64/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1961 - MAE: 0.2564 - val_loss: 0.5763 - val_MAE: 0.4566\n",
      "Epoch 65/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1955 - MAE: 0.2560 - val_loss: 0.5474 - val_MAE: 0.4379\n",
      "Epoch 66/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1969 - MAE: 0.2573 - val_loss: 0.5502 - val_MAE: 0.4351\n",
      "Epoch 67/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1951 - MAE: 0.2557 - val_loss: 0.5521 - val_MAE: 0.4375\n",
      "Epoch 68/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1952 - MAE: 0.2566 - val_loss: 0.5586 - val_MAE: 0.4397\n",
      "Epoch 69/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1959 - MAE: 0.2577 - val_loss: 0.5577 - val_MAE: 0.4414\n",
      "Epoch 70/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1949 - MAE: 0.2575 - val_loss: 0.5700 - val_MAE: 0.4477\n",
      "Epoch 71/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1924 - MAE: 0.2535 - val_loss: 0.5268 - val_MAE: 0.4289\n",
      "Epoch 72/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1991 - MAE: 0.2595 - val_loss: 0.5282 - val_MAE: 0.4174\n",
      "Epoch 73/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1963 - MAE: 0.2546 - val_loss: 0.5452 - val_MAE: 0.4358\n",
      "Epoch 74/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1965 - MAE: 0.2552 - val_loss: 0.5597 - val_MAE: 0.4447\n",
      "Epoch 75/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1902 - MAE: 0.2535 - val_loss: 0.5616 - val_MAE: 0.4458\n",
      "Epoch 76/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1951 - MAE: 0.2579 - val_loss: 0.5405 - val_MAE: 0.4275\n",
      "Epoch 77/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1937 - MAE: 0.2558 - val_loss: 0.5757 - val_MAE: 0.4565\n",
      "Epoch 78/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1935 - MAE: 0.2535 - val_loss: 0.5116 - val_MAE: 0.4130\n",
      "Epoch 79/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1927 - MAE: 0.2536 - val_loss: 0.6218 - val_MAE: 0.4698\n",
      "Epoch 80/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1895 - MAE: 0.2527 - val_loss: 0.5799 - val_MAE: 0.4592\n",
      "Epoch 81/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1890 - MAE: 0.2536 - val_loss: 0.5258 - val_MAE: 0.4174\n",
      "Epoch 82/1000\n",
      "630/630 [==============================] - 0s 39us/step - loss: 0.1920 - MAE: 0.2572 - val_loss: 0.5372 - val_MAE: 0.4260\n",
      "Epoch 83/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1878 - MAE: 0.2517 - val_loss: 0.5736 - val_MAE: 0.4527\n",
      "Epoch 84/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1872 - MAE: 0.2526 - val_loss: 0.5481 - val_MAE: 0.4341\n",
      "Epoch 85/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1873 - MAE: 0.2516 - val_loss: 0.5665 - val_MAE: 0.4409\n",
      "Epoch 86/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1881 - MAE: 0.2522 - val_loss: 0.6186 - val_MAE: 0.4734\n",
      "Epoch 87/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1877 - MAE: 0.2528 - val_loss: 0.5402 - val_MAE: 0.4333\n",
      "Epoch 88/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1842 - MAE: 0.2518 - val_loss: 0.5511 - val_MAE: 0.4415\n",
      "Epoch 89/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1837 - MAE: 0.2506 - val_loss: 0.5582 - val_MAE: 0.4387\n",
      "Epoch 90/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1816 - MAE: 0.2491 - val_loss: 0.5617 - val_MAE: 0.4418\n",
      "Epoch 91/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1855 - MAE: 0.2507 - val_loss: 0.5566 - val_MAE: 0.4388\n",
      "Epoch 92/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1806 - MAE: 0.2491 - val_loss: 0.5676 - val_MAE: 0.4428\n",
      "Epoch 93/1000\n",
      "630/630 [==============================] - 0s 39us/step - loss: 0.1813 - MAE: 0.2498 - val_loss: 0.4994 - val_MAE: 0.4024\n",
      "Epoch 94/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1902 - MAE: 0.2532 - val_loss: 0.5743 - val_MAE: 0.4506\n",
      "Epoch 95/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1804 - MAE: 0.2498 - val_loss: 0.5444 - val_MAE: 0.4323\n",
      "Epoch 96/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1796 - MAE: 0.2483 - val_loss: 0.5673 - val_MAE: 0.4446\n",
      "Epoch 97/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1813 - MAE: 0.2498 - val_loss: 0.5591 - val_MAE: 0.4381\n",
      "Epoch 98/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1815 - MAE: 0.2488 - val_loss: 0.6136 - val_MAE: 0.4713\n",
      "Epoch 99/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1801 - MAE: 0.2482 - val_loss: 0.5271 - val_MAE: 0.4165\n",
      "Epoch 100/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1809 - MAE: 0.2499 - val_loss: 0.5689 - val_MAE: 0.4454\n",
      "Epoch 101/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1793 - MAE: 0.2493 - val_loss: 0.5394 - val_MAE: 0.4234\n",
      "Epoch 102/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1803 - MAE: 0.2474 - val_loss: 0.5636 - val_MAE: 0.4443\n",
      "Epoch 103/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1771 - MAE: 0.2467 - val_loss: 0.5551 - val_MAE: 0.4411\n",
      "Epoch 104/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1854 - MAE: 0.2522 - val_loss: 0.5312 - val_MAE: 0.4235\n",
      "Epoch 105/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 0.1784 - MAE: 0.2476 - val_loss: 0.5666 - val_MAE: 0.4379\n",
      "Epoch 106/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1826 - MAE: 0.2489 - val_loss: 0.5413 - val_MAE: 0.4273\n",
      "Epoch 107/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1784 - MAE: 0.2465 - val_loss: 0.5501 - val_MAE: 0.4345\n",
      "Epoch 108/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1739 - MAE: 0.2449 - val_loss: 0.5312 - val_MAE: 0.4183\n",
      "Epoch 109/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1772 - MAE: 0.2451 - val_loss: 0.5981 - val_MAE: 0.4590\n",
      "Epoch 110/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1769 - MAE: 0.2430 - val_loss: 0.5876 - val_MAE: 0.4610\n",
      "Epoch 111/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1742 - MAE: 0.2453 - val_loss: 0.5576 - val_MAE: 0.4333\n",
      "Epoch 112/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1747 - MAE: 0.2459 - val_loss: 0.5399 - val_MAE: 0.4232\n",
      "Epoch 113/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1709 - MAE: 0.2422 - val_loss: 0.5548 - val_MAE: 0.4347\n",
      "Epoch 114/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1765 - MAE: 0.2462 - val_loss: 0.5981 - val_MAE: 0.4580\n",
      "Epoch 115/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1753 - MAE: 0.2471 - val_loss: 0.5551 - val_MAE: 0.4301\n",
      "Epoch 116/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1730 - MAE: 0.2432 - val_loss: 0.5369 - val_MAE: 0.4241\n",
      "Epoch 117/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1710 - MAE: 0.2436 - val_loss: 0.5776 - val_MAE: 0.4520\n",
      "Epoch 118/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1723 - MAE: 0.2451 - val_loss: 0.5493 - val_MAE: 0.4261\n",
      "Epoch 119/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1719 - MAE: 0.2421 - val_loss: 0.5659 - val_MAE: 0.4375\n",
      "Epoch 120/1000\n",
      "630/630 [==============================] - 0s 39us/step - loss: 0.1725 - MAE: 0.2427 - val_loss: 0.5558 - val_MAE: 0.4340\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 40us/step - loss: 0.1726 - MAE: 0.2437 - val_loss: 0.5366 - val_MAE: 0.4202\n",
      "Epoch 122/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1674 - MAE: 0.2407 - val_loss: 0.5763 - val_MAE: 0.4447\n",
      "Epoch 123/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1697 - MAE: 0.2405 - val_loss: 0.5458 - val_MAE: 0.4263\n",
      "Epoch 124/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1697 - MAE: 0.2428 - val_loss: 0.5318 - val_MAE: 0.4137\n",
      "Epoch 125/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1702 - MAE: 0.2416 - val_loss: 0.5218 - val_MAE: 0.4075\n",
      "Epoch 126/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1660 - MAE: 0.2418 - val_loss: 0.5965 - val_MAE: 0.4547\n",
      "Epoch 127/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1679 - MAE: 0.2423 - val_loss: 0.5435 - val_MAE: 0.4256\n",
      "Epoch 128/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1652 - MAE: 0.2399 - val_loss: 0.5441 - val_MAE: 0.4239\n",
      "Epoch 129/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1646 - MAE: 0.2406 - val_loss: 0.5590 - val_MAE: 0.4252\n",
      "Epoch 130/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1651 - MAE: 0.2395 - val_loss: 0.5218 - val_MAE: 0.4099\n",
      "Epoch 131/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1648 - MAE: 0.2404 - val_loss: 0.5426 - val_MAE: 0.4251\n",
      "Epoch 132/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1634 - MAE: 0.2380 - val_loss: 0.5653 - val_MAE: 0.4372\n",
      "Epoch 133/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1663 - MAE: 0.2394 - val_loss: 0.5190 - val_MAE: 0.4100\n",
      "Epoch 134/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1665 - MAE: 0.2419 - val_loss: 0.6009 - val_MAE: 0.4551\n",
      "Epoch 135/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1663 - MAE: 0.2396 - val_loss: 0.5770 - val_MAE: 0.4430\n",
      "Epoch 136/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 0.1623 - MAE: 0.2399 - val_loss: 0.5233 - val_MAE: 0.4035\n",
      "Epoch 137/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 0.1666 - MAE: 0.2408 - val_loss: 0.5793 - val_MAE: 0.4412\n",
      "Epoch 138/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1646 - MAE: 0.2388 - val_loss: 0.5657 - val_MAE: 0.4362\n",
      "Epoch 139/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1618 - MAE: 0.2381 - val_loss: 0.5497 - val_MAE: 0.4241\n",
      "Epoch 140/1000\n",
      "630/630 [==============================] - 0s 39us/step - loss: 0.1595 - MAE: 0.2362 - val_loss: 0.5351 - val_MAE: 0.4175\n",
      "Epoch 141/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1638 - MAE: 0.2390 - val_loss: 0.6125 - val_MAE: 0.4555\n",
      "Epoch 142/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1632 - MAE: 0.2382 - val_loss: 0.5403 - val_MAE: 0.4219\n",
      "Epoch 143/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1615 - MAE: 0.2380 - val_loss: 0.5611 - val_MAE: 0.4320\n",
      "Epoch 144/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1601 - MAE: 0.2362 - val_loss: 0.5463 - val_MAE: 0.4253\n",
      "Epoch 145/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1598 - MAE: 0.2380 - val_loss: 0.5437 - val_MAE: 0.4247\n",
      "Epoch 146/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1605 - MAE: 0.2378 - val_loss: 0.5671 - val_MAE: 0.4318\n",
      "Epoch 147/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1597 - MAE: 0.2372 - val_loss: 0.5460 - val_MAE: 0.4237\n",
      "Epoch 148/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1590 - MAE: 0.2350 - val_loss: 0.5381 - val_MAE: 0.4143\n",
      "Epoch 149/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1602 - MAE: 0.2374 - val_loss: 0.5197 - val_MAE: 0.4003\n",
      "Epoch 150/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1603 - MAE: 0.2388 - val_loss: 0.5894 - val_MAE: 0.4494\n",
      "Epoch 151/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1602 - MAE: 0.2374 - val_loss: 0.5444 - val_MAE: 0.4228\n",
      "Epoch 152/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1605 - MAE: 0.2369 - val_loss: 0.5097 - val_MAE: 0.3944\n",
      "Epoch 153/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1618 - MAE: 0.2359 - val_loss: 0.5509 - val_MAE: 0.4297\n",
      "Epoch 154/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1575 - MAE: 0.2353 - val_loss: 0.5521 - val_MAE: 0.4309\n",
      "Epoch 155/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1596 - MAE: 0.2382 - val_loss: 0.5905 - val_MAE: 0.4508\n",
      "Epoch 156/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1552 - MAE: 0.2368 - val_loss: 0.5403 - val_MAE: 0.4175\n",
      "Epoch 157/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1604 - MAE: 0.2397 - val_loss: 0.5470 - val_MAE: 0.4154\n",
      "Epoch 158/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1597 - MAE: 0.2396 - val_loss: 0.5547 - val_MAE: 0.4292\n",
      "Epoch 159/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1546 - MAE: 0.2325 - val_loss: 0.5282 - val_MAE: 0.4138\n",
      "Epoch 160/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1529 - MAE: 0.2328 - val_loss: 0.5546 - val_MAE: 0.4246\n",
      "Epoch 161/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1561 - MAE: 0.2356 - val_loss: 0.5312 - val_MAE: 0.4141\n",
      "Epoch 162/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1527 - MAE: 0.2324 - val_loss: 0.6058 - val_MAE: 0.4548\n",
      "Epoch 163/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1569 - MAE: 0.2390 - val_loss: 0.5565 - val_MAE: 0.4253\n",
      "Epoch 164/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1540 - MAE: 0.2346 - val_loss: 0.6454 - val_MAE: 0.4812\n",
      "Epoch 165/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1656 - MAE: 0.2411 - val_loss: 0.5283 - val_MAE: 0.4118\n",
      "Epoch 166/1000\n",
      "630/630 [==============================] - 0s 42us/step - loss: 0.1561 - MAE: 0.2357 - val_loss: 0.5486 - val_MAE: 0.4267\n",
      "Epoch 167/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1524 - MAE: 0.2327 - val_loss: 0.5718 - val_MAE: 0.4323\n",
      "Epoch 168/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1547 - MAE: 0.2353 - val_loss: 0.6073 - val_MAE: 0.4573\n",
      "Epoch 169/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1557 - MAE: 0.2352 - val_loss: 0.5789 - val_MAE: 0.4343\n",
      "Epoch 170/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1594 - MAE: 0.2367 - val_loss: 0.5982 - val_MAE: 0.4559\n",
      "Epoch 171/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1603 - MAE: 0.2385 - val_loss: 0.5495 - val_MAE: 0.4216\n",
      "Epoch 172/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1518 - MAE: 0.2335 - val_loss: 0.5702 - val_MAE: 0.4335\n",
      "Epoch 173/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1541 - MAE: 0.2327 - val_loss: 0.5507 - val_MAE: 0.4264\n",
      "Epoch 174/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1504 - MAE: 0.2331 - val_loss: 0.5382 - val_MAE: 0.4161\n",
      "Epoch 175/1000\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2099 - MAE: 0.262 - 0s 40us/step - loss: 0.1555 - MAE: 0.2370 - val_loss: 0.5738 - val_MAE: 0.4372\n",
      "Epoch 176/1000\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1595 - MAE: 0.247 - 0s 41us/step - loss: 0.1488 - MAE: 0.2310 - val_loss: 0.5786 - val_MAE: 0.4433\n",
      "Epoch 177/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1495 - MAE: 0.2317 - val_loss: 0.5630 - val_MAE: 0.4312\n",
      "Epoch 178/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1521 - MAE: 0.2324 - val_loss: 0.5461 - val_MAE: 0.4234\n",
      "Epoch 179/1000\n",
      "630/630 [==============================] - 0s 44us/step - loss: 0.1501 - MAE: 0.2308 - val_loss: 0.5699 - val_MAE: 0.4341\n",
      "Epoch 180/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 43us/step - loss: 0.1458 - MAE: 0.2293 - val_loss: 0.5509 - val_MAE: 0.4335\n",
      "Epoch 181/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 0.1504 - MAE: 0.2317 - val_loss: 0.5462 - val_MAE: 0.4264\n",
      "Epoch 182/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1499 - MAE: 0.2311 - val_loss: 0.5341 - val_MAE: 0.4175\n",
      "Epoch 183/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1473 - MAE: 0.2299 - val_loss: 0.5619 - val_MAE: 0.4318\n",
      "Epoch 184/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1511 - MAE: 0.2353 - val_loss: 0.5481 - val_MAE: 0.4259\n",
      "Epoch 185/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 0.1464 - MAE: 0.2307 - val_loss: 0.5682 - val_MAE: 0.4367\n",
      "Epoch 186/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1527 - MAE: 0.2317 - val_loss: 0.6079 - val_MAE: 0.4475\n",
      "Epoch 187/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1444 - MAE: 0.2306 - val_loss: 0.5372 - val_MAE: 0.4189\n",
      "Epoch 188/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 0.1434 - MAE: 0.2283 - val_loss: 0.5949 - val_MAE: 0.4430\n",
      "Epoch 189/1000\n",
      "630/630 [==============================] - 0s 44us/step - loss: 0.1469 - MAE: 0.2311 - val_loss: 0.5618 - val_MAE: 0.4336\n",
      "Epoch 190/1000\n",
      "630/630 [==============================] - 0s 44us/step - loss: 0.1453 - MAE: 0.2288 - val_loss: 0.5570 - val_MAE: 0.4368\n",
      "Epoch 191/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.1467 - MAE: 0.2313 - val_loss: 0.5464 - val_MAE: 0.4290\n",
      "Epoch 192/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.1425 - MAE: 0.2257 - val_loss: 0.5873 - val_MAE: 0.4450\n",
      "Epoch 193/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 0.1493 - MAE: 0.2317 - val_loss: 0.5750 - val_MAE: 0.4448\n",
      "실제관객:2421010.000, 예상관객 :2954057.000\n",
      "실제관객:277319.000, 예상관객 :426141.625\n",
      "실제관객:814587.000, 예상관객 :1487776.000\n",
      "실제관객:2658590.000, 예상관객 :4435977.000\n",
      "실제관객:2242510.000, 예상관객 :2456511.500\n",
      "실제관객:257193.000, 예상관객 :211304.750\n",
      "실제관객:551897.000, 예상관객 :704462.125\n",
      "실제관객:2434100.000, 예상관객 :2751527.000\n",
      "실제관객:327612.000, 예상관객 :542268.750\n",
      "실제관객:709929.000, 예상관객 :720443.875\n"
     ]
    }
   ],
   "source": [
    "seed = 8\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "df = pd.read_excel('./res/movie_score_re.xlsx')\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:, 2:8]\n",
    "Y = dataset[:, 1]\n",
    "\n",
    "mean_x = X.mean(axis=0)\n",
    "X_data = X - mean_x\n",
    "std_x = X_data.std(axis=0)\n",
    "X_data /= std_x\n",
    "\n",
    "mean_y = Y.mean(axis=0)\n",
    "Y_data = Y - mean_y\n",
    "std_y = Y_data.std(axis=0)\n",
    "Y_data /= std_y\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.25)\n",
    "\n",
    "X_train.shape\n",
    "X_test.shape\n",
    "Y_train.shape\n",
    "Y_test.shape\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=6, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['MAE'])\n",
    "\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)\n",
    "model.fit(X_data,Y_data, validation_split=0.25, epochs=1000, batch_size=20, callbacks=[early_stopping_callback])\n",
    "\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "\n",
    "Y_pre = (Y_prediction * std_y) + mean_y\n",
    "Y_t = (Y_test * std_y) + mean_y\n",
    "\n",
    "for i in range(10):\n",
    "    label = Y_t[i].astype(float)\n",
    "    prediction = Y_pre[i].astype(float)\n",
    "    print(\"실제관객:%.3f, 예상관객 :%.3f\"%(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
