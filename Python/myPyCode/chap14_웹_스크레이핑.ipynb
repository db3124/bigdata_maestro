{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 웹 브라우저로 웹 사이트 접속하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하나의 웹 사이트에 접속하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://search.naver.com/search.naver\n",
    "# ?\n",
    "# where=nexearch                             &\n",
    "# query=%ED%95%98%EB%82%A8%EC%8B%9C%EC%B2%AD &\n",
    "# sm=top_lve.agallgrpmapsipenpspp            &\n",
    "# ie=utf8\n",
    "\n",
    "\n",
    "# 보내는 요청을 처리할 주소(서버 주소)\n",
    "\n",
    "# ? : 서버주소와 추가정보들을 구분하는 기호\n",
    "\n",
    "# 추가정보들 : 파라미터. 1개 이상~ 여러개일 수 있다.\n",
    "# & : 파라미터 구분자\n",
    "# 파라미터명=값\n",
    "\n",
    "# query 값으로 원하는 검색어를 입력하면, 원하는 결과를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "\n",
    "url = 'www.naver.com'\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_search_url = 'https://search.naver.com/search.naver?query='\n",
    "search_word = '파이썬'\n",
    "url = naver_search_url + search_word\n",
    "\n",
    "webbrowser.open(url) # 새로운 창\n",
    "# webbrowser.open_new(url) # 기본 브라우저의 새 창 또는 탭. 차이 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_search_url = 'www.google.com/search?#q='\n",
    "search_word = '파이썬'\n",
    "url = naver_search_url+search_word\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여러 개의 웹 사이트에 접속하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['www.naver.com', 'www.daum.net', 'www.google.com']\n",
    "\n",
    "for url in urls:\n",
    "    webbrowser.open(url)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 웹 스크레이핑을 위한 기본 지식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터의 요청과 응답 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:\\BigData\\projects\\myPyCode\\HTML_example.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:\\BigData\\projects\\myPyCode\\HTML_example.html\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "        <head>\n",
    "            <title>이것은 HTML 예제</title>\n",
    "            <meta charset = \"UTF-8\" /> \n",
    "        </head>\n",
    "        \n",
    "        <body>\n",
    "            <h1>출간된 책 정보</h1>\n",
    "            <p id=\"book_title\">이해가 쏙쏙 되는 파이썬</p>\n",
    "            <p id=\"author\">홍길동</p>\n",
    "            <p id=\"publisher\">위키북스 출판사</p>\n",
    "            <p id=\"year\">2018</p>\n",
    "        </body>\n",
    "    </html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹 페이지의 HTML 소스 갖고 오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('https://www.google.co.kr')\n",
    "r\n",
    "# type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"ko\"><head><meta content'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"ko\"><head><meta content'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "html = requests.get('https://www.google.co.kr').text\n",
    "html[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML 소스코드를 분석하고 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 찾고 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html><body><div><span><a href=\"https://www.naver.com\">naver</a><a href=\"https://www.google.com\">google</a><a href=\"https://www.daum.net\">daum</a></span></div></body></html>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 테스트용 html 코드\n",
    "html = '''<!DOCTYPE html><html><body><div><span>\\\n",
    "<a href=https://www.naver.com>naver</a>\\\n",
    "<a href=https://www.google.com>google</a>\\\n",
    "<a href=https://www.daum.net>daum</a>\\\n",
    "</span></div></body></html>'''\n",
    "\n",
    "# BeautifulSoup를 이용해 HTML 소스를 파싱\n",
    "soup = BeautifulSoup(html, 'lxml') # lxml: parer\n",
    "soup\n",
    "# type(soup) # 파싱된 정보를 포함한 문서 객체 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <body>\n",
      "  <div>\n",
      "   <span>\n",
      "    <a href=\"https://www.naver.com\">\n",
      "     naver\n",
      "    </a>\n",
      "    <a href=\"https://www.google.com\">\n",
      "     google\n",
      "    </a>\n",
      "    <a href=\"https://www.daum.net\">\n",
      "     daum\n",
      "    </a>\n",
      "   </span>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())\n",
    "# type(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.naver.com\">naver</a>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup.find('태그') 해당 태그의 첫 번째 요소\n",
    "soup.find('a')\n",
    "# type(soup.find('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'naver'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a').get_text()\n",
    "# type(soup.find('a').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.naver.com\">naver</a>,\n",
       " <a href=\"https://www.google.com\">google</a>,\n",
       " <a href=\"https://www.daum.net\">daum</a>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 해당 태그의 모든 요소 반환\n",
    "soup.find_all('a')\n",
    "# type(soup.find_all('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver\n",
      "google\n",
      "daum\n"
     ]
    }
   ],
   "source": [
    "site_names = soup.find_all('a')\n",
    "# ResultSet 객체는 get_text() 메서드를 갖지 않음.\n",
    "\n",
    "for site_name in site_names:\n",
    "    print(site_name.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 테스트용 HTML 코드\n",
    "html2 = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>작품과 작가 모음</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>책 정보</h1>\n",
    "        <p class=\"book_title\">토지</p>\n",
    "        <p class=\"author\">박경리</p>\n",
    "        \n",
    "        <p class=\"book_title\">태백산맥</p>\n",
    "        <p class=\"author\">조정래</p>\n",
    "        \n",
    "        <p class=\"book_title\">감옥으로부터의 사색</p>\n",
    "        <p class=\"author\">신영복</p>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup2 = BeautifulSoup(html2, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>작품과 작가 모음</title>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<h1>책 정보</h1>\n",
       "<p class=\"book_title\">토지</p>\n",
       "<p class=\"author\">박경리</p>\n",
       "<p class=\"book_title\">태백산맥</p>\n",
       "<p class=\"author\">조정래</p>\n",
       "<p class=\"book_title\">감옥으로부터의 사색</p>\n",
       "<p class=\"author\">신영복</p>\n",
       "</body>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>책 정보</h1>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.body.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"book_title\">토지</p>,\n",
       " <p class=\"author\">박경리</p>,\n",
       " <p class=\"book_title\">태백산맥</p>,\n",
       " <p class=\"author\">조정래</p>,\n",
       " <p class=\"book_title\">감옥으로부터의 사색</p>,\n",
       " <p class=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"book_title\">토지</p>,\n",
       " <p class=\"book_title\">태백산맥</p>,\n",
       " <p class=\"book_title\">감옥으로부터의 사색</p>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find_all('p', {'class': 'book_title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토지 + 박경리\n",
      "태백산맥 + 조정래\n",
      "감옥으로부터의 사색 + 신영복\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "soup2 = BeautifulSoup(html2, 'lxml')\n",
    "\n",
    "book_titles = soup2.find_all('p', {'class': 'book_title'})\n",
    "authors = soup2.find_all('p', {'class': 'author'})\n",
    "\n",
    "for book_title, author in zip(book_titles, authors):\n",
    "    print(book_title.get_text(), '+', author.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-145044df2bbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mauthor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauthor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mlst_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlst_title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_title\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mlst_author\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlst_author\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "soup2 = BeautifulSoup(html2, 'lxml')\n",
    "\n",
    "book_titles = soup2.find_all('p', {'class': 'book_title'})\n",
    "authors = soup2.find_all('p', {'class': 'author'})\n",
    "\n",
    "lst_title = [0] * 3\n",
    "lst_author = [0] *3\n",
    "\n",
    "for book_title, author in zip(book_titles, authors):\n",
    "    book_title = book_title.get_text()\n",
    "    author = author.get_text()\n",
    "    \n",
    "    lst_title = lst_title.append(book_title)\n",
    "    lst_author = lst_author.append(author)\n",
    "    \n",
    "df_title = pd.DataFrame(lst_title)\n",
    "df_author = pd.DataFrame(lst_author)\n",
    "df = df_title.join(df_author)\n",
    "    \n",
    "df_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1>책 정보</h1>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('body h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"book_title\">토지</p>,\n",
       " <p class=\"author\">박경리</p>,\n",
       " <p class=\"book_title\">태백산맥</p>,\n",
       " <p class=\"author\">조정래</p>,\n",
       " <p class=\"book_title\">감옥으로부터의 사색</p>,\n",
       " <p class=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('body p') # 자손 선택자(복합-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"book_title\">토지</p>,\n",
       " <p class=\"author\">박경리</p>,\n",
       " <p class=\"book_title\">태백산맥</p>,\n",
       " <p class=\"author\">조정래</p>,\n",
       " <p class=\"book_title\">감옥으로부터의 사색</p>,\n",
       " <p class=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('body>p') # 자식 선택자(복합-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"book_title\">토지</p>,\n",
       " <p class=\"author\">박경리</p>,\n",
       " <p class=\"book_title\">태백산맥</p>,\n",
       " <p class=\"author\">조정래</p>,\n",
       " <p class=\"book_title\">감옥으로부터의 사색</p>,\n",
       " <p class=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('p') # 단일 선택자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"book_title\">토지</p>,\n",
       " <p class=\"book_title\">태백산맥</p>,\n",
       " <p class=\"book_title\">감옥으로부터의 사색</p>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('p.book_title') # 클래스 선택자(복합-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"author\">박경리</p>,\n",
       " <p class=\"author\">조정래</p>,\n",
       " <p class=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('p.author') # 클래스 선택자(복합-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup2.select('p#book_title') # id 선택자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile C:/BigData/projects/myPyCode/HTML_example_my_site.html\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "        <head>\n",
    "            <meta charset=\"UTF-8\" />\n",
    "            <title>사이트 모음</title>\n",
    "        </head>\n",
    "        <body>\n",
    "            \n",
    "        </body>\n",
    "    </html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 브라우저의 요소 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 줄 바꿈으로 가독성 높이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:/BigData/projects/myPyCode/br_example_constitution.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:/BigData/projects/myPyCode/br_example_constitution.html\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "        <head>\n",
    "            <meta charset=\"UTF-8\" />\n",
    "            <title>줄 바꿈 테스트 예제</title>\n",
    "        </head>\n",
    "        <body>\n",
    "            <p id=\"title\"><b>대한민국헌법</b></p>\n",
    "            <p class=\"content\">제1조<br />①대한민국은 민주공화국이다.<br />②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>\n",
    "            <p class=\"content\">제2조<br />①대한민국의 국민이 되는 요건은 법률로 정한다.<br />②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다.</p>\n",
    "        </body>\n",
    "    </html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국헌법\n",
      "제1조①대한민국은 민주공화국이다.②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.\n",
      "제2조①대한민국의 국민이 되는 요건은 법률로 정한다.②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "f = open('C:/BigData/projects/myPyCode/br_example_constitution.html', encoding='UTF-8')\n",
    "\n",
    "html_source = f.read()\n",
    "f.close()\n",
    "\n",
    "soup = BeautifulSoup(html_source, 'lxml')\n",
    "\n",
    "title = soup.find('p', {\"id\":\"title\"})\n",
    "contents = soup.find_all('p', {\"class\":\"content\"})\n",
    "\n",
    "print(title.get_text())\n",
    "for content in contents:\n",
    "    print(content.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_newline(soup_html):\n",
    "    br_to_newlines = soup_html.find_all('br')\n",
    "    \n",
    "    for br_to_newline in br_to_newlines:\n",
    "        br_to_newline.replace_with('\\n')\n",
    "    \n",
    "    return soup_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국헌법 \n",
      "\n",
      "제1조\n",
      "①대한민국은 민주공화국이다.\n",
      "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다. \n",
      "\n",
      "제2조\n",
      "①대한민국의 국민이 되는 요건은 법률로 정한다.\n",
      "②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_source, 'lxml')\n",
    "\n",
    "title = soup.find('p', {\"id\":\"title\"})\n",
    "contents = soup.find_all('p', {\"class\":\"content\"})\n",
    "\n",
    "print(title.get_text(), '\\n')\n",
    "\n",
    "for content in contents:\n",
    "    content1 = replace_newline(content)\n",
    "    print(content1.get_text(), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 웹 사이트에서 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹 스크레이핑 시 주의 사항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순위 데이터를 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.alexa.com/topsites/countries/KR\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.alexa.com/topsites/countries/KR'\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, 'lxml')\n",
    "\n",
    "# p 태그의 요소 안에서 a 태그의 요소를 찾음\n",
    "website_ranking = soup_website_ranking.select('div.td.DescriptionCell>p>a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/siteinfo/google.com\">Google.com</a>,\n",
       " <a href=\"/siteinfo/naver.com\">Naver.com</a>,\n",
       " <a href=\"/siteinfo/youtube.com\">Youtube.com</a>,\n",
       " <a href=\"/siteinfo/daum.net\">Daum.net</a>,\n",
       " <a href=\"/siteinfo/tmall.com\">Tmall.com</a>,\n",
       " <a href=\"/siteinfo/tistory.com\">Tistory.com</a>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_ranking_address = [website_ranking_element.get_text() for website_ranking_element in website_ranking]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google.com',\n",
       " 'Naver.com',\n",
       " 'Youtube.com',\n",
       " 'Daum.net',\n",
       " 'Tmall.com',\n",
       " 'Tistory.com']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking_address[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Top Sites in South Korea]\n",
      "1: Google.com\n",
      "2: Naver.com\n",
      "3: Youtube.com\n",
      "4: Daum.net\n",
      "5: Tmall.com\n",
      "6: Tistory.com\n"
     ]
    }
   ],
   "source": [
    "print(\"[Top Sites in South Korea]\")\n",
    "for k in range(6):\n",
    "    print('{0}: {1}'.format(k+1, website_ranking_address[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naver.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daum.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tmall.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tistory.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Website\n",
       "0   Google.com\n",
       "1    Naver.com\n",
       "2  Youtube.com\n",
       "3     Daum.net\n",
       "4    Tmall.com\n",
       "5  Tistory.com"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "website_ranking_dict = {'Website': website_ranking_address}\n",
    "df = pd.DataFrame(website_ranking_dict, columns = ['Website'])\n",
    "index = range(1, len(website_ranking_address)+1)\n",
    "df[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주간 음악 순위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"ellipsis\">눈 (Feat. 이문세)</span>,\n",
       " <span class=\"ellipsis\">기억의 빈자리</span>,\n",
       " <span class=\"ellipsis\">선물</span>,\n",
       " <span class=\"ellipsis\">Beautiful</span>,\n",
       " <span class=\"ellipsis\">좋아</span>,\n",
       " <span class=\"ellipsis\">피카부 (Peek-A-Boo)</span>]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://music.naver.com/listen/history/index.nhn?type=TOTAL&year=2017&month=12&week=1&page=1'\n",
    "html_music = requests.get(url).text\n",
    "soup_music = BeautifulSoup(html_music, 'lxml')\n",
    "\n",
    "# 노래 제목 찾기\n",
    "titles = soup_music.select('a._title>span.ellipsis')\n",
    "titles[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['눈 (Feat. 이문세)', '기억의 빈자리', '선물', 'Beautiful', '좋아', '피카부 (Peek-A-Boo)']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_titles = [title.get_text() for title in titles]\n",
    "music_titles[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zion.T'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가수 이름 찾기\n",
    "artists = soup_music.select('a._artist>span.ellipsis')\n",
    "artists[0].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zion.T',\n",
       " '나얼',\n",
       " '멜로망스(Melomance)',\n",
       " 'Wanna One(워너원)',\n",
       " 'Red Velvet (레드벨벳)',\n",
       " '윤종신']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_artists = [artist.get_text().strip() for artist in artists]\n",
    "music_artists[0:6] # 가수 중에 태그가 다른 가수가 있어 목록에서 빠짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zion.T'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists = soup_music.select('td._artist>a')\n",
    "artists[0].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'민서'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[4].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zion.T',\n",
       " '나얼',\n",
       " '멜로망스(Melomance)',\n",
       " 'Wanna One(워너원)',\n",
       " '민서',\n",
       " 'Red Velvet (레드벨벳)']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_artists = [artist.get_text().strip() for artist in artists]\n",
    "music_artists[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 눈 (Feat. 이문세) / Zion.T\n",
      "2: 기억의 빈자리 / 나얼\n",
      "3: 선물 / 멜로망스(Melomance)\n",
      "4: Beautiful / Wanna One(워너원)\n",
      "5: 좋아 / 민서\n",
      "6: 피카부 (Peek-A-Boo) / Red Velvet (레드벨벳)\n",
      "7: 좋니 / 윤종신\n",
      "8: WHERE YOU AT / 뉴이스트 W\n",
      "9: LIKEY / TWICE(트와이스)\n",
      "10: 그때의 나, 그때의 우리 / 어반자카파\n",
      "11: 있다면 / 뉴이스트 W\n",
      "12: 뻔한 이별 (PROD. 13) / 소유 (SOYOU..\n",
      "13: 하루만 / 뉴이스트 W\n",
      "14: 여보세요 / 뉴이스트\n",
      "15: DNA / 방탄소년단\n",
      "16: 갖고 싶어 / Wanna One(워너원)\n",
      "17: 에너제틱 (Energetic) / Wanna One(워너원)\n",
      "18: 특별해 / 젝스키스\n",
      "19: 연애소설 (Feat. 아이유) / 에픽하이 (EPIK HIGH)\n",
      "20: 썸 탈꺼야 / 볼빨간사춘기\n",
      "21: 웃어줘 / 젝스키스\n",
      "22: 지금까지 행복했어요 (BAEKHO SOLO) / 뉴이스트 W\n",
      "23: 그리워하다 / 비투비\n",
      "24: GOOD LOVE (ARON SOLO) / 뉴이스트 W\n",
      "25: Twilight / Wanna One(워너원)\n",
      "26: 밤편지 / 아이유(IU)\n",
      "27: PARADISE (REN SOLO) / 뉴이스트 W\n",
      "28: WITH (JR SOLO) / 뉴이스트 W\n",
      "29: 봄날 / 방탄소년단\n",
      "30: Nothing Without You (Intro.) / Wanna One(워너원)\n",
      "31: 아프지 마요 / 젝스키스\n",
      "32: 시차 (We Are) (Feat. 로꼬 & GRAY) / 우원재\n",
      "33: 오랜만이에요 / 젝스키스\n",
      "34: 백허그 / 젝스키스\n",
      "35: MOVE / 태민(TAEMIN)\n",
      "36: 슬픈 노래 / 젝스키스\n",
      "37: 나의 사춘기에게 / 볼빨간사춘기\n",
      "38: Havana (Feat. Young Thug) / Camila Cabello\n",
      "39: 네가 필요해 / 젝스키스\n",
      "40: 술끊자 / 젝스키스\n",
      "41: 다신 / 젝스키스\n",
      "42: REALLY REALLY / WINNER\n",
      "43: 느낌이 와 / 젝스키스\n",
      "44: 첫눈처럼 너에게 가겠다 / 에일리\n",
      "45: 현기증 / 젝스키스\n",
      "46: 나의 밤 나의 너 / 성시경\n",
      "47: Snowman / Sia\n",
      "48: 세 단어 / 젝스키스\n",
      "49: 비도 오고 그래서 (Feat. 신용재) / 헤이즈(Heize)\n",
      "50: 빈차 (Feat. 오혁) / 에픽하이 (EPIK HIGH)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://music.naver.com/listen/history/index.nhn?type=TOTAL&year=2017&month=12&week=1&page=1'\n",
    "html_music = requests.get(url).text\n",
    "soup_music = BeautifulSoup(html_music, 'lxml')\n",
    "\n",
    "titles = soup_music.select('a._title>span.ellipsis')\n",
    "artists = soup_music.select('td._artist>a')\n",
    "\n",
    "music_titles = [title.get_text() for title in titles]\n",
    "music_artists = [artist.get_text().strip() for artist in artists]\n",
    "\n",
    "for k in range(len(music_titles)):\n",
    "    print('{0}: {1} / {2}'.format(k+1, music_titles[k], music_artists[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_titles_artists = {}\n",
    "order = 0\n",
    "\n",
    "for music_title, music_artist in zip(music_titles, music_artists):\n",
    "    order = order + 1\n",
    "    music_titles_artists[order] = [music_title, music_artist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['선물', '멜로망스(Melomance)']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_titles_artists[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/BigData/projects/myPyCode/NaverMusicTop100.txt']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "\n",
    "naver_music_url = 'https://music.naver.com/listen/history/index.nhn?type=TOTAL&year=2017&month=12&week=1&page='\n",
    "\n",
    "# 네이버 뮤직 주소를 입력하면 노래 제목과 아티스트를 반환\n",
    "def naver_music(url):\n",
    "    html_music = requests.get(url).text\n",
    "    soup_music = BeautifulSoup(html_music, 'lxml')\n",
    "\n",
    "    titles = soup_music.select('a._title span.ellipsis')\n",
    "    artists = soup_music.select('td._artist>a')\n",
    "\n",
    "    music_titles = [title.get_text() for title in titles]\n",
    "    music_artists = [artist.get_text().strip() for artist in artists]\n",
    "    \n",
    "    return music_titles, music_artists\n",
    "\n",
    "# 노래 제목과 아티스트를 저장할 파일 이름을 폴더와 함께 지정\n",
    "file_name = 'C:/BigData/projects/myPyCode/NaverMusicTop100.txt'\n",
    "\n",
    "f = open(file_name, 'w')\n",
    "\n",
    "# 각 페이지에는 50개의 노래 제목과 아티스트가 추출됨\n",
    "for page in range(2):\n",
    "    naver_music_url_page = naver_music_url + str(page+1)\n",
    "    naver_music_titles, naver_music_artists = naver_music(naver_music_url_page)\n",
    "    \n",
    "    # 추출된 노래 제목과 아티스트를 파일에 저장\n",
    "    for k in range(len(naver_music_titles)):\n",
    "        f.write('{0:2d}: {1} / {2}\\n'.format(page*50 + k+1, naver_music_titles[k],naver_music_artists[k]))\n",
    "        \n",
    "        \n",
    "f.close()\n",
    "\n",
    "glob.glob(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
